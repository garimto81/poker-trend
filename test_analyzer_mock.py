# -*- coding: utf-8 -*-
"""
í¬ì»¤ íŠ¸ë Œë“œ ë¶„ì„ê¸° ëª¨ì˜ í…ŒìŠ¤íŠ¸ (Mock Test)
ì‹¤ì œ API í‚¤ ì—†ì´ë„ ì‹œìŠ¤í…œ ë¡œì§ì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

import os
import json
import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Any
from dataclasses import dataclass
import random

@dataclass
class MockVideoData:
    """ëª¨ì˜ ë¹„ë””ì˜¤ ë°ì´í„° êµ¬ì¡°"""
    video_id: str
    title: str
    description: str
    published_at: str
    view_count: int
    like_count: int
    comment_count: int
    channel_title: str
    duration: str
    keyword_matched: str
    relevance_score: float = 0.0

class MockPokerTrendAnalyzer:
    """ëª¨ì˜ í¬ì»¤ íŠ¸ë Œë“œ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.target_keywords = [
            "Holdem", "WSOP", "Cashgame", "PokerStars", 
            "GGPoker", "GTO", "WPT"
        ]
        self.collected_videos: List[MockVideoData] = []
        
        # ëª¨ì˜ ë¹„ë””ì˜¤ ë°ì´í„° ìƒì„±
        self.sample_videos = self._generate_sample_videos()
    
    def _generate_sample_videos(self) -> List[MockVideoData]:
        """ìƒ˜í”Œ ë¹„ë””ì˜¤ ë°ì´í„° ìƒì„±"""
        videos = []
        
        # ê° í‚¤ì›Œë“œë³„ë¡œ ìƒ˜í”Œ ë¹„ë””ì˜¤ ìƒì„±
        for keyword in self.target_keywords:
            for i in range(10):  # í‚¤ì›Œë“œë‹¹ 10ê°œ
                video = MockVideoData(
                    video_id=f"{keyword.lower()}_{i+1:03d}",
                    title=f"{keyword} Strategy Guide #{i+1} - Advanced Tips",
                    description=f"Learn advanced {keyword} strategies from professional players. "
                               f"This comprehensive guide covers key concepts and tactics. "
                               f"Perfect for intermediate to advanced players looking to improve.",
                    published_at=(datetime.now() - timedelta(days=random.randint(1, 30))).isoformat(),
                    view_count=random.randint(1000, 100000),
                    like_count=random.randint(50, 5000),
                    comment_count=random.randint(10, 500),
                    channel_title=f"Poker Pro {keyword}",
                    duration="PT10M30S",
                    keyword_matched=keyword,
                    relevance_score=random.uniform(0.6, 1.0)
                )
                videos.append(video)
        
        return videos
    
    def _calculate_relevance_score(self, text: str, keyword: str) -> float:
        """ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        text_lower = text.lower()
        keyword_lower = keyword.lower()
        
        # ê¸°ë³¸ ì ìˆ˜
        base_score = 0.5 if keyword_lower in text_lower else 0.0
        
        # í¬ì»¤ ìš©ì–´ ë³´ë„ˆìŠ¤
        poker_terms = [
            'poker', 'tournament', 'cash', 'game', 'strategy', 'bluff',
            'fold', 'bet', 'raise', 'call', 'all-in', 'final table'
        ]
        
        bonus_score = sum(0.05 for term in poker_terms if term in text_lower)
        title_bonus = 0.3 if keyword_lower in text_lower[:100] else 0.0
        
        return min(1.0, base_score + bonus_score + title_bonus)
    
    async def collect_videos_for_keyword(self, keyword: str, max_results: int = 50) -> List[MockVideoData]:
        """í‚¤ì›Œë“œë³„ ë¹„ë””ì˜¤ ìˆ˜ì§‘ ëª¨ì˜"""
        print(f"ëª¨ì˜ ìˆ˜ì§‘: í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì¤‘...")
        
        # ì‹¤ì œ API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜ (ì§€ì—°)
        await asyncio.sleep(0.2)
        
        # í•´ë‹¹ í‚¤ì›Œë“œ ë¹„ë””ì˜¤ í•„í„°ë§
        keyword_videos = [v for v in self.sample_videos if v.keyword_matched == keyword]
        
        # ê´€ë ¨ì„± ì ìˆ˜ ì¬ê³„ì‚°
        for video in keyword_videos:
            video.relevance_score = self._calculate_relevance_score(
                video.title + " " + video.description, keyword
            )
        
        # ìƒìœ„ ê²°ê³¼ ë°˜í™˜
        keyword_videos.sort(key=lambda x: x.relevance_score, reverse=True)
        return keyword_videos[:max_results]
    
    async def collect_all_videos(self) -> List[MockVideoData]:
        """ì „ì²´ í‚¤ì›Œë“œ ë¹„ë””ì˜¤ ìˆ˜ì§‘ ëª¨ì˜"""
        print("ëª¨ì˜ ìˆ˜ì§‘: ì „ì²´ í‚¤ì›Œë“œ ë¹„ë””ì˜¤ ìˆ˜ì§‘ ì‹œì‘...")
        
        all_videos = []
        
        # ëª¨ë“  í‚¤ì›Œë“œì— ëŒ€í•´ ë¹„ë™ê¸° ìˆ˜ì§‘
        tasks = []
        for keyword in self.target_keywords:
            task = self.collect_videos_for_keyword(keyword, 10)  # í‚¤ì›Œë“œë‹¹ 10ê°œ
            tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        
        for i, keyword_videos in enumerate(results):
            all_videos.extend(keyword_videos)
            print(f"í‚¤ì›Œë“œ '{self.target_keywords[i]}': {len(keyword_videos)}ê°œ ë¹„ë””ì˜¤ ìˆ˜ì§‘")
        
        # ì¤‘ë³µ ì œê±° ë° ìƒìœ„ 50ê°œ ì„ íƒ
        unique_videos = {}
        for video in all_videos:
            if video.video_id not in unique_videos:
                unique_videos[video.video_id] = video
        
        self.collected_videos = list(unique_videos.values())
        self.collected_videos.sort(key=lambda x: x.relevance_score, reverse=True)
        self.collected_videos = self.collected_videos[:50]
        
        print(f"ì´ {len(self.collected_videos)}ê°œ ê³ ìœ  ë¹„ë””ì˜¤ ìˆ˜ì§‘ ì™„ë£Œ")
        return self.collected_videos
    
    def mock_gemini_analysis(self, videos: List[MockVideoData]) -> Dict[str, Any]:
        """Gemini AI ë¶„ì„ ëª¨ì˜"""
        print("ëª¨ì˜ ë¶„ì„: Gemini AI íŠ¸ë Œë“œ ë¶„ì„ ì¤‘...")
        
        # í‚¤ì›Œë“œë³„ ë¹„ë””ì˜¤ ìˆ˜ ê³„ì‚°
        keyword_counts = {}
        for video in videos:
            keyword_counts[video.keyword_matched] = keyword_counts.get(video.keyword_matched, 0) + 1
        
        # ê°€ì¥ ë§ì€ í‚¤ì›Œë“œ ì°¾ê¸°
        most_trending = max(keyword_counts.keys(), key=lambda k: keyword_counts[k])
        
        # ëª¨ì˜ íŠ¸ë Œë“œ ìƒì„±
        mock_trends = [
            {
                "trend_title": f"{most_trending} ì „ëµì˜ ê¸‰ë¶€ìƒ",
                "trend_description": f"{most_trending} ê´€ë ¨ ì½˜í…ì¸ ê°€ í¬ê²Œ ì¦ê°€í•˜ê³  ìˆìœ¼ë©°, íŠ¹íˆ ê³ ê¸‰ ì „ëµì— ëŒ€í•œ ê´€ì‹¬ì´ ë†’ì•„ì§€ê³  ìˆìŠµë‹ˆë‹¤.",
                "confidence_score": 0.85,
                "supporting_videos": [v.video_id for v in videos if v.keyword_matched == most_trending][:3],
                "trend_category": "emerging",
                "keywords": [most_trending, "strategy", "advanced"],
                "impact_level": "meso",
                "content_potential": "ë†’ìŒ",
                "recommended_action": f"{most_trending} ì´ˆê¸‰ì ê°€ì´ë“œ ì½˜í…ì¸  ì œì‘ ê¶Œì¥"
            },
            {
                "trend_title": "í¬ì»¤ êµìœ¡ ì½˜í…ì¸  ìˆ˜ìš” ì¦ê°€",
                "trend_description": "ì „ëµì  í¬ì»¤ êµìœ¡ì— ëŒ€í•œ ìˆ˜ìš”ê°€ ì§€ì†ì ìœ¼ë¡œ ì¦ê°€í•˜ê³  ìˆìœ¼ë©°, ìƒì„¸í•œ í•´ì„¤ì´ í¬í•¨ëœ ì½˜í…ì¸ ê°€ ì¸ê¸°ë¥¼ ëŒê³  ìˆìŠµë‹ˆë‹¤.",
                "confidence_score": 0.72,
                "supporting_videos": [v.video_id for v in videos[:5]],
                "trend_category": "stable",
                "keywords": ["education", "strategy", "guide"],
                "impact_level": "micro",
                "content_potential": "ì¤‘ê°„",
                "recommended_action": "ë‹¨ê³„ë³„ í•™ìŠµ ì‹œë¦¬ì¦ˆ ì œì‘"
            }
        ]
        
        return {
            "analysis_date": datetime.now().isoformat(),
            "total_videos_analyzed": len(videos),
            "trends": mock_trends,
            "keyword_insights": {
                "most_trending": most_trending,
                "emerging_themes": ["advanced strategy", "tournament play"],
                "declining_themes": ["basic rules"]
            },
            "content_recommendations": [
                f"{most_trending} ì´ˆê¸‰ì ì™„ë²½ ê°€ì´ë“œ",
                "í¬ì»¤ ì‹¤ìˆ˜ TOP 10ê³¼ í•´ê²°ë²•",
                "í”„ë¡œ í”Œë ˆì´ì–´ ì¸í„°ë·° ì‹œë¦¬ì¦ˆ",
                "ë¼ì´ë¸Œ ê²Œì„ vs ì˜¨ë¼ì¸ ê²Œì„ ë¹„êµ",
                "í¬ì»¤ ìˆ˜í•™ ì‰½ê²Œ ë°°ìš°ê¸°"
            ]
        }
    
    def save_results(self, videos: List[MockVideoData], analysis: Dict[str, Any], 
                    filename_prefix: str = "mock_poker_trend_analysis") -> str:
        """ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{filename_prefix}_{timestamp}.json"
        
        # ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        videos_dict = []
        for video in videos:
            videos_dict.append({
                'video_id': video.video_id,
                'title': video.title,
                'description': video.description,
                'published_at': video.published_at,
                'view_count': video.view_count,
                'like_count': video.like_count,
                'comment_count': video.comment_count,
                'channel_title': video.channel_title,
                'duration': video.duration,
                'keyword_matched': video.keyword_matched,
                'relevance_score': video.relevance_score,
                'url': f"https://www.youtube.com/watch?v={video.video_id} (MOCK)"
            })
        
        result = {
            'metadata': {
                'analysis_time': datetime.now().isoformat(),
                'target_keywords': self.target_keywords,
                'total_videos_collected': len(videos),
                'analyzer_version': '1.0.0-mock',
                'note': 'ì´ê²ƒì€ ëª¨ì˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼ì…ë‹ˆë‹¤. ì‹¤ì œ YouTube ë°ì´í„°ê°€ ì•„ë‹™ë‹ˆë‹¤.'
            },
            'videos': videos_dict,
            'gemini_analysis': analysis
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        print(f"ëª¨ì˜ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filename}")
        return filename
    
    def generate_summary_report(self, analysis: Dict[str, Any]) -> str:
        """ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = f"""
í¬ì»¤ íŠ¸ë Œë“œ ë¶„ì„ ë¦¬í¬íŠ¸ (ëª¨ì˜ í…ŒìŠ¤íŠ¸)
ë¶„ì„ ì¼ì‹œ: {analysis.get('analysis_date', 'Unknown')}
ë¶„ì„ ë¹„ë””ì˜¤ ìˆ˜: {analysis.get('total_videos_analyzed', 0)}ê°œ

ì‹ë³„ëœ íŠ¸ë Œë“œ:
"""
        
        trends = analysis.get('trends', [])
        for i, trend in enumerate(trends, 1):
            report += f"""
{i}. {trend.get('trend_title', 'Unknown')}
   - ì¹´í…Œê³ ë¦¬: {trend.get('trend_category', 'unknown')} ({trend.get('impact_level', 'unknown')} ë ˆë²¨)
   - ì‹ ë¢°ë„: {trend.get('confidence_score', 0):.2f}
   - ì„¤ëª…: {trend.get('trend_description', 'No description')}
   - ì½˜í…ì¸  ì ì¬ë ¥: {trend.get('content_potential', 'unknown')}
   - ì¶”ì²œ ì•¡ì…˜: {trend.get('recommended_action', 'No action')}
"""
        
        keyword_insights = analysis.get('keyword_insights', {})
        report += f"""
í‚¤ì›Œë“œ ì¸ì‚¬ì´íŠ¸:
- ê°€ì¥ íŠ¸ë Œë”©: {keyword_insights.get('most_trending', 'Unknown')}
- ë– ì˜¤ë¥´ëŠ” ì£¼ì œ: {', '.join(keyword_insights.get('emerging_themes', []))}
- ì¤„ì–´ë“œëŠ” ì£¼ì œ: {', '.join(keyword_insights.get('declining_themes', []))}

ì½˜í…ì¸  ì œì‘ ê¶Œì¥ì‚¬í•­:
"""
        
        recommendations = analysis.get('content_recommendations', [])
        for i, rec in enumerate(recommendations, 1):
            report += f"{i}. {rec}\n"
        
        report += "\n[ì£¼ì˜] ì´ê²ƒì€ ëª¨ì˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼ì…ë‹ˆë‹¤."
        
        return report

async def main():
    """ë©”ì¸ ëª¨ì˜ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("í¬ì»¤ íŠ¸ë Œë“œ ë¶„ì„ê¸° ëª¨ì˜ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    try:
        # ëª¨ì˜ ë¶„ì„ê¸° ì´ˆê¸°í™”
        analyzer = MockPokerTrendAnalyzer()
        
        # 1. ë¹„ë””ì˜¤ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
        print("1. í‚¤ì›Œë“œë³„ YouTube ë¹„ë””ì˜¤ ìˆ˜ì§‘ ëª¨ì˜...")
        videos = await analyzer.collect_all_videos()
        print(f"âœ“ ì´ {len(videos)}ê°œ ë¹„ë””ì˜¤ ìˆ˜ì§‘ ì™„ë£Œ")
        print()
        
        # 2. ê´€ë ¨ì„± ì ìˆ˜ í…ŒìŠ¤íŠ¸
        if videos:
            sample_video = videos[0]
            score = analyzer._calculate_relevance_score(
                sample_video.title + " " + sample_video.description,
                sample_video.keyword_matched
            )
            print(f"2. ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° í…ŒìŠ¤íŠ¸:")
            print(f"   ìƒ˜í”Œ ë¹„ë””ì˜¤: {sample_video.title}")
            print(f"   í‚¤ì›Œë“œ: {sample_video.keyword_matched}")
            print(f"   ê´€ë ¨ì„± ì ìˆ˜: {score:.3f}")
            print("âœ“ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚° ì•Œê³ ë¦¬ì¦˜ ì •ìƒ ì‘ë™")
            print()
        
        # 3. Gemini AI ë¶„ì„ ëª¨ì˜
        print("3. Gemini AI íŠ¸ë Œë“œ ë¶„ì„ ëª¨ì˜...")
        analysis = analyzer.mock_gemini_analysis(videos)
        print(f"âœ“ {len(analysis.get('trends', []))}ê°œ íŠ¸ë Œë“œ ì‹ë³„ ì™„ë£Œ")
        print()
        
        # 4. ê²°ê³¼ ì €ì¥ í…ŒìŠ¤íŠ¸
        print("4. ë¶„ì„ ê²°ê³¼ ì €ì¥ í…ŒìŠ¤íŠ¸...")
        saved_file = analyzer.save_results(videos, analysis)
        print(f"âœ“ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {saved_file}")
        print()
        
        # 5. ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
        print("5. ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
        print("=" * 60)
        summary = analyzer.generate_summary_report(analysis)
        print(summary)
        
        print("=" * 60)
        print("ëª¨ì˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("âœ“ ëª¨ë“  í•µì‹¬ ê¸°ëŠ¥ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
        print(f"âœ“ ìƒì„¸ ê²°ê³¼ëŠ” {saved_file} íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        
        return True
        
    except Exception as e:
        print(f"âŒ ëª¨ì˜ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    if success:
        print("\nğŸ‰ ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ì‹¤ì œ API í‚¤ë¥¼ ì„¤ì •í•˜ë©´ ë°”ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâŒ ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")