#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ê°œì„ ëœ í¬ì»¤ íŠ¸ë Œë“œ ë¶„ì„ê¸° - ì‡¼ì¸  ì œì‘ìš© AI ì¸ì‚¬ì´íŠ¸ í¬í•¨
"""

import os
import json
import logging
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
import google.generativeai as genai
from googleapiclient.discovery import build
import requests

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
env_path = Path(__file__).parent.parent / '.env'
if env_path.exists():
    load_dotenv(env_path)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class EnhancedTrendAnalyzer:
    def __init__(self):
        self.youtube = build('youtube', 'v3', developerKey=os.getenv('YOUTUBE_API_KEY'))
        genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
        self.gemini_model = genai.GenerativeModel('gemini-1.5-flash')
        self.slack_webhook = os.getenv('SLACK_WEBHOOK_URL')
        
        self.keywords = [
            'poker', 'holdem', 'wsop', 'wpt', 'ept', 
            'pokerstars', 'ggpoker', 'triton poker'
        ]
    
    def collect_video_data(self, max_results=5):
        """YouTube ì˜ìƒ ë°ì´í„° ìˆ˜ì§‘"""
        logger.info("Starting video data collection...")
        all_videos = []
        
        for keyword in self.keywords:
            try:
                request = self.youtube.search().list(
                    part='snippet',
                    q=keyword,
                    type='video',
                    maxResults=max_results,
                    order='viewCount',
                    publishedAfter='2025-08-04T00:00:00Z'
                )
                
                response = request.execute()
                videos = response.get('items', [])
                
                for video in videos:
                    video_data = {
                        'video_id': video['id']['videoId'],
                        'title': video['snippet']['title'],
                        'channel_title': video['snippet']['channelTitle'],
                        'published_at': video['snippet']['publishedAt'],
                        'keyword': keyword,
                        'url': f"https://youtube.com/watch?v={video['id']['videoId']}"
                    }
                    
                    # ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    details = self.youtube.videos().list(
                        part='statistics,contentDetails',
                        id=video['id']['videoId']
                    ).execute()
                    
                    if details['items']:
                        stats = details['items'][0]['statistics']
                        content = details['items'][0]['contentDetails']
                        
                        video_data.update({
                            'view_count': int(stats.get('viewCount', 0)),
                            'like_count': int(stats.get('likeCount', 0)),
                            'comment_count': int(stats.get('commentCount', 0)),
                            'duration': content.get('duration', '')
                        })
                    
                    all_videos.append(video_data)
                
                logger.info(f"Collected {len(videos)} videos for keyword: {keyword}")
                
            except Exception as e:
                logger.error(f"Error collecting data for {keyword}: {e}")
        
        logger.info(f"Total videos collected: {len(all_videos)}")
        return all_videos
    
    def create_enhanced_ai_prompt(self, top_videos):
        """ì‡¼ì¸  ì œì‘ìš© ê°œì„ ëœ AI í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        titles_summary = "\n".join([
            f"{i+1}. {video.get('title', '')} - {video.get('view_count', 0):,} views"
            for i, video in enumerate(top_videos[:5])
        ])
        
        prompt = f"""
You are a YouTube Shorts strategy expert specializing in poker content. Analyze these TOP performing videos and provide actionable insights for viral shorts creation.

TOP 5 PERFORMING VIDEOS:
{titles_summary}

PROVIDE DETAILED ANALYSIS:

1. VIRAL SUCCESS PATTERNS
- What specific elements make these titles click-worthy?
- Identify the psychological triggers being used
- Essential keywords that drive discoverability

2. OPTIMAL CONTENT STRATEGY
- Recommended video length for maximum engagement
- Best practices for hook creation (first 3 seconds)
- Pacing and editing recommendations

3. IMMEDIATE ACTION ITEMS (3 Specific Shorts Ideas)
Format each as:
TITLE: [Compelling title with emojis]
CONCEPT: [15-second storyline breakdown]
HOOK: [First 3 seconds strategy]
VISUAL ELEMENTS: [Camera angles, editing style]
HASHTAGS: [5 optimized tags]
SUCCESS PROBABILITY: [High/Medium/Low with reasoning]

4. THUMBNAIL OPTIMIZATION
- Most effective facial expressions and poses
- Color psychology for poker content
- Text overlay best practices

5. MARKET OPPORTUNITIES
- Underserved niches in current poker content
- Trending topics to capitalize on
- Differentiation strategies from competitors

6. CONTENT CALENDAR SUGGESTIONS
- Best posting times based on current trends
- Weekly content themes
- Seasonal opportunities

Make all recommendations immediately actionable. Focus on strategies a creator can implement TODAY to increase their viral potential.
"""
        return prompt
    
    def generate_enhanced_insights(self, videos):
        """ê°œì„ ëœ AI ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        logger.info("Generating enhanced AI insights...")
        
        try:
            top_videos = sorted(videos, key=lambda x: x.get('view_count', 0), reverse=True)[:10]
            prompt = self.create_enhanced_ai_prompt(top_videos)
            
            response = self.gemini_model.generate_content(prompt)
            return response.text
            
        except Exception as e:
            logger.error(f"AI insight generation failed: {e}")
            return "AI ì¸ì‚¬ì´íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    
    def create_slack_report(self, videos, ai_insights):
        """Slack ë¦¬í¬íŠ¸ ìƒì„±"""
        top_videos = sorted(videos, key=lambda x: x.get('view_count', 0), reverse=True)[:5]
        total_views = sum(v.get('view_count', 0) for v in videos)
        
        blocks = [
            {
                "type": "header",
                "text": {
                    "type": "plain_text",
                    "text": "ğŸ° Enhanced Poker Trend Analysis"
                }
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"ğŸ“… {datetime.now().strftime('%Y-%m-%d')}\nğŸ“Š Videos: {len(videos)}\nğŸ‘€ Total Views: {total_views:,}"
                }
            },
            {
                "type": "divider"
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "*ğŸ† TOP 5 VIDEOS*"
                }
            }
        ]
        
        for i, video in enumerate(top_videos, 1):
            title = video.get('title', '')[:60]
            views = video.get('view_count', 0)
            channel = video.get('channel_title', '')
            url = video.get('url', '')
            
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"{i}. <{url}|{title}>\n   {views:,} views â€¢ {channel}"
                }
            })
        
        blocks.extend([
            {
                "type": "divider"
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "*ğŸ¤– AI INSIGHTS FOR SHORTS CREATION*\n_See detailed analysis in report file_"
                }
            }
        ])
        
        return {"blocks": blocks}
    
    def send_slack_notification(self, message):
        """Slack ì•Œë¦¼ ì „ì†¡"""
        try:
            response = requests.post(self.slack_webhook, json=message)
            return response.status_code == 200
        except Exception as e:
            logger.error(f"Slack notification failed: {e}")
            return False
    
    def run_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        logger.info("=" * 60)
        logger.info("ENHANCED POKER TREND ANALYSIS STARTED")
        logger.info("=" * 60)
        
        # 1. ë°ì´í„° ìˆ˜ì§‘
        videos = self.collect_video_data()
        
        # 2. AI ì¸ì‚¬ì´íŠ¸ ìƒì„±
        ai_insights = self.generate_enhanced_insights(videos)
        
        # 3. ë¦¬í¬íŠ¸ ìƒì„±
        report_data = {
            "timestamp": datetime.now().isoformat(),
            "total_videos": len(videos),
            "enhanced_ai_insights": ai_insights,
            "top_videos": sorted(videos, key=lambda x: x.get('view_count', 0), reverse=True)[:10],
            "all_videos": videos
        }
        
        # 4. íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = Path(__file__).parent / 'reports' / f'enhanced_analysis_{timestamp}.json'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"Report saved: {report_path}")
        
        # 5. Slack ì•Œë¦¼
        slack_message = self.create_slack_report(videos, ai_insights)
        if self.send_slack_notification(slack_message):
            logger.info("Slack notification sent successfully")
        else:
            logger.error("Failed to send Slack notification")
        
        # 6. ê²°ê³¼ ìš”ì•½
        logger.info("=" * 60)
        logger.info("ANALYSIS COMPLETED SUCCESSFULLY")
        logger.info("=" * 60)
        logger.info(f"Videos analyzed: {len(videos)}")
        logger.info(f"AI insights generated: {'âœ“' if ai_insights else 'âœ—'}")
        logger.info(f"Report saved: âœ“")
        logger.info(f"Slack sent: {'âœ“' if self.send_slack_notification else 'âœ—'}")
        
        return report_data

if __name__ == "__main__":
    analyzer = EnhancedTrendAnalyzer()
    analyzer.run_analysis()