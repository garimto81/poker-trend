#!/usr/bin/env python3
"""
Enhanced YouTube í¬ì»¤ íŠ¸ë Œë“œ ë¶„ì„ - ì •ë°€ ë¶„ì„ ë²„ì „
GEMINI_API_KEY, YOUTUBE_API_KEY, SLACK_WEBHOOK_URL ì‚¬ìš©
"""

import os
import sys
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Tuple
import requests
from collections import Counter
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import google.generativeai as genai

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜ í™•ì¸
REQUIRED_ENV_VARS = [
    'YOUTUBE_API_KEY',
    'SLACK_WEBHOOK_URL',
    'GEMINI_API_KEY'
]

missing_vars = []
for var in REQUIRED_ENV_VARS:
    if not os.getenv(var):
        missing_vars.append(var)
        logger.error(f"Missing required environment variable: {var}")

if missing_vars:
    logger.error(f"Missing environment variables: {', '.join(missing_vars)}")
    sys.exit(1)

# API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
youtube = build('youtube', 'v3', developerKey=os.getenv('YOUTUBE_API_KEY'))
slack_webhook_url = os.getenv('SLACK_WEBHOOK_URL')
genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
gemini_model = genai.GenerativeModel('gemini-pro')


class EnhancedYouTubeTrendAnalyzer:
    """í–¥ìƒëœ YouTube í¬ì»¤ íŠ¸ë Œë“œ ë¶„ì„ê¸°"""
    
    def __init__(self):
        # ê³ ì •ëœ ê²€ìƒ‰ í‚¤ì›Œë“œ (ì§ì ‘ ì„¤ì •)
        self.search_terms = [
            'poker', 'í¬ì»¤', 'holdem', 'í™€ë¤', 
            'WSOP', 'WPT', 'EPT', 
            'PokerStars', 'GGPoker', 
            'tournament', 'í† ë„ˆë¨¼íŠ¸',
            'cash game', 'ìºì‹œê²Œì„',
            'poker strategy', 'í¬ì»¤ ì „ëµ'
        ]
        self.categories = {
            'tournament': ['WSOP', 'WPT', 'EPT', 'í† ë„ˆë¨¼íŠ¸', 'tournament', 'final table'],
            'online': ['í¬ì»¤ìŠ¤íƒ€ì¦ˆ', 'PokerStars', 'GGPoker', 'ì˜¨ë¼ì¸ í¬ì»¤', 'online poker'],
            'education': ['ì „ëµ', 'strategy', 'ê°•ì˜', 'tutorial', 'how to', 'tips'],
            'entertainment': ['í•˜ì´ë¼ì´íŠ¸', 'highlights', 'ì¬ë¯¸ìˆëŠ”', 'funny', 'best', 'epic'],
            'pro_player': ['Phil Ivey', 'Daniel Negreanu', 'Phil Hellmuth', 'Doyle Brunson'],
            'cash_game': ['cash game', 'ìºì‹œê²Œì„', 'high stakes', 'í•˜ì´ìŠ¤í…Œì´í¬ìŠ¤']
        }
        self.trend_keywords = []
    
    def collect_videos(self, lookback_hours: int = 48) -> List[Dict]:
        """YouTubeì—ì„œ í¬ì»¤ ê´€ë ¨ ì˜ìƒ ìˆ˜ì§‘ (ë” ë§ì€ ë°ì´í„°)"""
        all_videos = []
        published_after = (datetime.utcnow() - timedelta(hours=lookback_hours)).isoformat() + 'Z'
        
        for term in self.search_terms:
            try:
                # ì—¬ëŸ¬ ì •ë ¬ ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰
                for order in ['viewCount', 'relevance', 'date']:
                    request = youtube.search().list(
                        q=term,
                        part='snippet',
                        type='video',
                        maxResults=25,
                        order=order,
                        publishedAfter=published_after,
                        videoDuration='short'  # ì‡¼ì¸ ì— ì í•©í•œ ì§§ì€ ì˜ìƒ
                    )
                    response = request.execute()
                    
                    for item in response.get('items', []):
                        video_id = item['id']['videoId']
                        if not any(v.get('video_id') == video_id for v in all_videos):
                            all_videos.append({
                                'video_id': video_id,
                                'title': item['snippet']['title'],
                                'channel_title': item['snippet']['channelTitle'],
                                'published_at': item['snippet']['publishedAt'],
                                'thumbnail_url': item['snippet']['thumbnails']['high']['url'],
                                'description': item['snippet']['description'][:200]
                            })
                        
            except HttpError as e:
                logger.error(f"YouTube API error for term '{term}': {e}")
                continue
        
        # ì¤‘ë³µ ì œê±° í›„ ìƒìœ„ 100ê°œë§Œ
        unique_videos = list({v['video_id']: v for v in all_videos}.values())
        return self.enrich_video_data(unique_videos[:100])
    
    def enrich_video_data(self, videos: List[Dict]) -> List[Dict]:
        """ë¹„ë””ì˜¤ ìƒì„¸ ì •ë³´ ì¶”ê°€ (ë” ë§ì€ ë©”íŠ¸ë¦­ìŠ¤)"""
        if not videos:
            return []
        
        video_ids = [v['video_id'] for v in videos]
        
        # í†µê³„ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ë°°ì¹˜ ì²˜ë¦¬)
        enriched_videos = []
        for i in range(0, len(video_ids), 50):
            batch_ids = video_ids[i:i+50]
            
            try:
                stats_request = youtube.videos().list(
                    part='statistics,contentDetails',
                    id=','.join(batch_ids)
                )
                stats_response = stats_request.execute()
                
                stats_map = {
                    item['id']: {
                        'statistics': item['statistics'],
                        'duration': item['contentDetails']['duration']
                    }
                    for item in stats_response.get('items', [])
                }
                
                for video in videos[i:i+50]:
                    if video['video_id'] in stats_map:
                        stats = stats_map[video['video_id']]['statistics']
                        video['view_count'] = int(stats.get('viewCount', 0))
                        video['like_count'] = int(stats.get('likeCount', 0))
                        video['comment_count'] = int(stats.get('commentCount', 0))
                        video['duration'] = stats_map[video['video_id']]['duration']
                        
                        # ì¶”ê°€ ë©”íŠ¸ë¦­ìŠ¤ ê³„ì‚°
                        views = video['view_count']
                        if views > 0:
                            video['engagement_rate'] = ((video['like_count'] + video['comment_count']) / views) * 100
                            video['like_ratio'] = (video['like_count'] / views) * 100
                        else:
                            video['engagement_rate'] = 0
                            video['like_ratio'] = 0
                        
                        # ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜ ê³„ì‚°
                        published_time = datetime.fromisoformat(video['published_at'].replace('Z', '+00:00'))
                        hours_since_publish = (datetime.now(published_time.tzinfo) - published_time).total_seconds() / 3600
                        video['views_per_hour'] = views / hours_since_publish if hours_since_publish > 0 else 0
                        
                        enriched_videos.append(video)
                        
            except HttpError as e:
                logger.error(f"Error fetching video statistics: {e}")
        
        return enriched_videos
    
    def analyze_trends(self, videos: List[Dict]) -> Dict[str, Any]:
        """ê³ ê¸‰ íŠ¸ë Œë“œ ë¶„ì„"""
        if not videos:
            return {'total_videos': 0, 'trending_videos': [], 'categories': {}}
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ
        all_titles = ' '.join([v['title'] for v in videos])
        words = all_titles.lower().split()
        
        # ë¶ˆìš©ì–´ ì œì™¸í•˜ê³  ë¹ˆë„ ê³„ì‚°
        stopwords = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'was', 'are', 'were'}
        word_freq = Counter([word for word in words if word not in stopwords and len(word) > 3])
        self.trend_keywords = word_freq.most_common(15)
        
        # ë™ì  í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±° (ìƒˆë¡œìš´ íŠ¸ë Œë“œ ë°œê²¬ì‹œ)
        trending_words = [kw[0] for kw in self.trend_keywords[:10]]
        logger.info(f"Current trending keywords: {trending_words}")
        
        # ì±„ë„ë³„ í†µê³„
        channel_counts = Counter([v['channel_title'] for v in videos])
        top_channels = channel_counts.most_common(5)
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
        category_stats = {cat: [] for cat in self.categories}
        
        for video in videos:
            # íŠ¸ë Œë“œ ìŠ¤ì½”ì–´ ê³„ì‚° (ê°œì„ ëœ ì•Œê³ ë¦¬ì¦˜)
            views = video.get('view_count', 0)
            engagement = video.get('engagement_rate', 0)
            views_per_hour = video.get('views_per_hour', 0)
            
            # ë³µí•© íŠ¸ë Œë“œ ìŠ¤ì½”ì–´
            video['trend_score'] = (
                (views * 0.3) +  # ì´ ì¡°íšŒìˆ˜
                (views_per_hour * 100 * 0.4) +  # ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜ (ê°€ì¤‘ì¹˜ ë†’ìŒ)
                (engagement * 1000 * 0.3)  # ì°¸ì—¬ìœ¨
            )
            
            # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
            video['category'] = self.categorize_video(video)
            category_stats[video['category']].append(video)
        
        # íŠ¸ë Œë“œ ìŠ¤ì½”ì–´ë¡œ ì •ë ¬
        videos.sort(key=lambda x: x.get('trend_score', 0), reverse=True)
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        category_summary = {}
        for cat, vids in category_stats.items():
            if vids:
                category_summary[cat] = {
                    'count': len(vids),
                    'avg_views': sum(v.get('view_count', 0) for v in vids) / len(vids),
                    'avg_engagement': sum(v.get('engagement_rate', 0) for v in vids) / len(vids)
                }
        
        return {
            'total_videos': len(videos),
            'trending_videos': videos[:10],  # TOP 10
            'avg_views': sum(v.get('view_count', 0) for v in videos) / len(videos),
            'avg_engagement': sum(v.get('engagement_rate', 0) for v in videos) / len(videos),
            'trending_keywords': self.trend_keywords,
            'category_breakdown': category_summary,
            'hourly_avg_views': sum(v.get('views_per_hour', 0) for v in videos) / len(videos),
            'search_keywords': self.search_terms,  # ê²€ìƒ‰ì— ì‚¬ìš©ëœ í‚¤ì›Œë“œ
            'top_channels': top_channels  # ê°€ì¥ ë§ì€ ì˜ìƒì„ ìƒì„±í•œ ì±„ë„
        }
    
    def categorize_video(self, video: Dict) -> str:
        """ë¹„ë””ì˜¤ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ê°œì„ ëœ ë²„ì „)"""
        title_lower = video['title'].lower()
        desc_lower = video.get('description', '').lower()
        
        category_scores = {}
        for category, keywords in self.categories.items():
            score = sum(
                2 if keyword.lower() in title_lower else 1 if keyword.lower() in desc_lower else 0
                for keyword in keywords
            )
            category_scores[category] = score
        
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì¹´í…Œê³ ë¦¬ ë°˜í™˜
        best_category = max(category_scores.items(), key=lambda x: x[1])
        return best_category[0] if best_category[1] > 0 else 'general'
    
    def generate_ai_suggestions(self, analysis_data: Dict) -> str:
        """Gemini AIë¥¼ ì‚¬ìš©í•œ ì‡¼ì¸  ì œì‘ ì œì•ˆ"""
        try:
            # íŠ¸ë Œë“œ ë°ì´í„° ìš”ì•½
            trend_summary = f"""
            í˜„ì¬ í¬ì»¤ YouTube íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼:
            - ì´ ë¶„ì„ ì˜ìƒ: {analysis_data['total_videos']}ê°œ
            - í‰ê·  ì¡°íšŒìˆ˜: {format_number(analysis_data['avg_views'])}
            - í‰ê·  ì°¸ì—¬ìœ¨: {analysis_data['avg_engagement']:.2f}%
            - ì‹œê°„ë‹¹ í‰ê·  ì¡°íšŒìˆ˜: {format_number(analysis_data['hourly_avg_views'])}
            
            ì¸ê¸° í‚¤ì›Œë“œ: {', '.join([kw[0] for kw in analysis_data['trending_keywords'][:10]])}
            
            ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:
            {self._format_category_stats(analysis_data['category_breakdown'])}
            
            TOP 5 íŠ¸ë Œë”© ì˜ìƒ:
            {self._format_top_videos(analysis_data['trending_videos'][:5])}
            """
            
            prompt = f"""
            ë‹¹ì‹ ì€ í¬ì»¤ ì½˜í…ì¸  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ YouTube íŠ¸ë Œë“œ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ 
            ë°”ì´ëŸ´ ê°€ëŠ¥ì„±ì´ ë†’ì€ í¬ì»¤ ì‡¼ì¸  ì•„ì´ë””ì–´ë¥¼ 5ê°œ ì œì•ˆí•´ì£¼ì„¸ìš”.
            
            {trend_summary}
            
            ê° ì•„ì´ë””ì–´ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
            1. ì œëª© (í¥ë¯¸ë¡œìš´ í›„í‚¹ í¬í•¨)
            2. í•µì‹¬ ì½˜í…ì¸  (30ì´ˆ ë¶„ëŸ‰)
            3. ì˜ˆìƒ íƒ€ê²Ÿì¸µ
            4. ì°¨ë³„í™” í¬ì¸íŠ¸
            
            íŠ¸ë Œë“œë¥¼ ë°˜ì˜í•˜ë˜ ë…ì°½ì ì´ê³  ì‹œì²­ìì˜ í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” ì½˜í…ì¸ ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.
            """
            
            response = gemini_model.generate_content(prompt)
            return response.text
            
        except Exception as e:
            logger.error(f"Gemini AI error: {e}")
            return "AI ì œì•ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def generate_trend_analysis(self, analysis_data: Dict) -> str:
        """Gemini AIë¥¼ ì‚¬ìš©í•œ íŠ¸ë Œë“œ ë¶„ì„ í•œì¤„ ìš”ì•½"""
        try:
            trend_summary = f"""
            í¬ì»¤ YouTube íŠ¸ë Œë“œ ë°ì´í„°:
            - ì´ ì˜ìƒ: {analysis_data['total_videos']}ê°œ
            - í‰ê·  ì¡°íšŒìˆ˜: {format_number(analysis_data['avg_views'])}
            - ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜: {format_number(analysis_data['hourly_avg_views'])}
            - TOP í‚¤ì›Œë“œ: {', '.join([kw[0] for kw in analysis_data['trending_keywords'][:5]])}
            - ì£¼ìš” ì¹´í…Œê³ ë¦¬: {max(analysis_data['category_breakdown'].items(), key=lambda x: x[1]['count'])[0] if analysis_data['category_breakdown'] else 'N/A'}
            """
            
            prompt = f"""
            ë‹¤ìŒ í¬ì»¤ íŠ¸ë Œë“œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ í˜„ì¬ íŠ¸ë Œë“œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
            
            {trend_summary}
            
            ìš”ì•½ì€ ë‹¤ìŒ ìš”ì†Œë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
            - ê°€ì¥ ì£¼ëª©í•  ë§Œí•œ íŠ¸ë Œë“œ
            - ì‹œì²­ìë“¤ì˜ ê´€ì‹¬ì‚¬
            - í–¥í›„ ì „ë§
            
            50ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê³  í†µì°°ë ¥ ìˆê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """
            
            response = gemini_model.generate_content(prompt)
            return response.text.strip()
            
        except Exception as e:
            logger.error(f"Trend analysis error: {e}")
            return "í˜„ì¬ í¬ì»¤ ì½˜í…ì¸ ëŠ” í† ë„ˆë¨¼íŠ¸ì™€ ì „ëµ ì½˜í…ì¸ ê°€ ì£¼ë„í•˜ê³  ìˆìŠµë‹ˆë‹¤."
    
    def _format_category_stats(self, category_stats: Dict) -> str:
        """ì¹´í…Œê³ ë¦¬ í†µê³„ í¬ë§·íŒ…"""
        lines = []
        for cat, stats in category_stats.items():
            lines.append(f"- {cat}: {stats['count']}ê°œ (í‰ê·  ì¡°íšŒìˆ˜: {format_number(stats['avg_views'])}, ì°¸ì—¬ìœ¨: {stats['avg_engagement']:.2f}%)")
        return '\n'.join(lines)
    
    def _format_top_videos(self, videos: List[Dict]) -> str:
        """TOP ì˜ìƒ ì •ë³´ í¬ë§·íŒ…"""
        lines = []
        for i, video in enumerate(videos, 1):
            lines.append(f"{i}. {video['title'][:50]}... - ì¡°íšŒìˆ˜: {format_number(video['view_count'])}, ì°¸ì—¬ìœ¨: {video['engagement_rate']:.2f}%")
        return '\n'.join(lines)


def send_enhanced_slack_webhook(data: Dict[str, Any], ai_suggestions: str, trend_analysis: str):
    """í–¥ìƒëœ Slack Webhook ë©”ì‹œì§€ ì „ì†¡"""
    
    # í˜„ì¬ ì‹œê°„ (í•œêµ­ ì‹œê°„)
    kst_time = datetime.now() + timedelta(hours=9)
    
    # ë©”ì‹œì§€ ë¸”ë¡ êµ¬ì„±
    blocks = [
        {
            "type": "header",
            "text": {
                "type": "plain_text",
                "text": f"ğŸ° í¬ì»¤ YouTube íŠ¸ë Œë“œ ì •ë°€ ë¶„ì„ ({kst_time.strftime('%Y.%m.%d %H:%M')} KST)"
            }
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "*ğŸ“Š ì „ì²´ íŠ¸ë Œë“œ ìš”ì•½*"
            }
        },
        {
            "type": "section",
            "fields": [
                {
                    "type": "mrkdwn",
                    "text": f"*ì´ ë¶„ì„ ì˜ìƒ:*\n{data['total_videos']}ê°œ"
                },
                {
                    "type": "mrkdwn",
                    "text": f"*í‰ê·  ì¡°íšŒìˆ˜:*\n{format_number(data['avg_views'])}íšŒ"
                },
                {
                    "type": "mrkdwn",
                    "text": f"*í‰ê·  ì°¸ì—¬ìœ¨:*\n{data['avg_engagement']:.2f}%"
                },
                {
                    "type": "mrkdwn",
                    "text": f"*ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜:*\n{format_number(data['hourly_avg_views'])}íšŒ/h"
                }
            ]
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ:* {', '.join([f'`{kw}`' for kw in data.get('search_keywords', [])[:10]])}"
            }
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*ğŸ¬ TOP ì±„ë„:* {', '.join([f'{ch[0]} ({ch[1]}ê°œ)' for ch in data.get('top_channels', [])[:3]])}"
            }
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*ğŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„:* {trend_analysis}"
            }
        },
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*ğŸ”¥ í•« í‚¤ì›Œë“œ:* {', '.join([f'`{kw[0]}`' for kw in data['trending_keywords'][:8]])}"
            }
        },
        {"type": "divider"},
        {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": "*ğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„*"
            }
        }
    ]
    
    # ì¹´í…Œê³ ë¦¬ í†µê³„ ì¶”ê°€
    category_text = []
    for cat, stats in data['category_breakdown'].items():
        emoji = {
            'tournament': 'ğŸ†',
            'online': 'ğŸ’»',
            'education': 'ğŸ“š',
            'entertainment': 'ğŸ­',
            'pro_player': 'ğŸ‘¤',
            'cash_game': 'ğŸ’°'
        }.get(cat, 'ğŸ“Œ')
        category_text.append(f"{emoji} *{cat}*: {stats['count']}ê°œ (í‰ê·  {format_number(stats['avg_views'])}íšŒ)")
    
    blocks.append({
        "type": "section",
        "text": {
            "type": "mrkdwn",
            "text": '\n'.join(category_text)
        }
    })
    
    blocks.append({"type": "divider"})
    
    # TOP 5 íŠ¸ë Œë”© ì˜ìƒ
    blocks.append({
        "type": "section",
        "text": {
            "type": "mrkdwn",
            "text": "*ğŸš€ TOP 5 ê¸‰ìƒìŠ¹ ì˜ìƒ*"
        }
    })
    
    for i, video in enumerate(data['trending_videos'][:5], 1):
        # ì œëª©ì— í•˜ì´í¼ë§í¬ ì¶”ê°€
        video_url = f"https://youtube.com/watch?v={video['video_id']}"
        
        blocks.append({
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"*{i}. <{video_url}|{video['title'][:60]}...>*"
            },
            "fields": [
                {
                    "type": "mrkdwn",
                    "text": f"ğŸ“º *{video['channel_title']}*"
                },
                {
                    "type": "mrkdwn", 
                    "text": f"ğŸ‘ï¸ *{format_number(video['view_count'])}* ì¡°íšŒ"
                },
                {
                    "type": "mrkdwn",
                    "text": f"ğŸ’• *{format_number(video['like_count'])}* ì¢‹ì•„ìš”"
                },
                {
                    "type": "mrkdwn",
                    "text": f"âš¡ *{format_number(video['views_per_hour'])}*/ì‹œê°„"
                }
            ],
            "accessory": {
                "type": "image",
                "image_url": video['thumbnail_url'],
                "alt_text": video['title']
            }
        })
    
    blocks.append({"type": "divider"})
    
    # AI ì œì•ˆ ì¶”ê°€
    blocks.append({
        "type": "section",
        "text": {
            "type": "mrkdwn",
            "text": "*ğŸ¤– AI ì‡¼ì¸  ì œì‘ ì œì•ˆ*"
        }
    })
    
    # AI ì œì•ˆì„ ë¸”ë¡ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
    ai_text = ai_suggestions[:2000] if ai_suggestions else "AI ì œì•ˆì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    blocks.append({
        "type": "section",
        "text": {
            "type": "mrkdwn",
            "text": ai_text
        }
    })
    
    # Webhook ì „ì†¡
    payload = {
        "blocks": blocks,
        "text": "ğŸ° í¬ì»¤ YouTube íŠ¸ë Œë“œ ì •ë°€ ë¶„ì„"
    }
    
    try:
        response = requests.post(
            slack_webhook_url,
            json=payload,
            headers={'Content-Type': 'application/json'}
        )
        
        if response.status_code == 200:
            logger.info("Enhanced Slack webhook sent successfully")
        else:
            logger.error(f"Slack webhook error: {response.status_code} - {response.text}")
            
    except Exception as e:
        logger.error(f"Error sending Slack webhook: {e}")


def format_number(num: float) -> str:
    """ìˆ«ì í¬ë§·íŒ… (ê°œì„ ëœ ë²„ì „)"""
    if num >= 1000000:
        return f"{num/1000000:.1f}M"
    elif num >= 10000:
        return f"{num/1000:.0f}K"
    elif num >= 1000:
        return f"{num/1000:.1f}K"
    else:
        return str(int(num))


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("Starting enhanced YouTube poker trend analysis...")
    
    try:
        # YouTube íŠ¸ë Œë“œ ë¶„ì„
        analyzer = EnhancedYouTubeTrendAnalyzer()
        logger.info("Collecting YouTube videos with enhanced parameters...")
        videos = analyzer.collect_videos(lookback_hours=48)  # 48ì‹œê°„ ë°ì´í„°
        
        logger.info(f"Collected {len(videos)} videos for analysis")
        
        # ê³ ê¸‰ íŠ¸ë Œë“œ ë¶„ì„
        logger.info("Performing advanced trend analysis...")
        analysis_result = analyzer.analyze_trends(videos)
        
        # AI ì œì•ˆ ìƒì„±
        logger.info("Generating AI suggestions...")
        ai_suggestions = analyzer.generate_ai_suggestions(analysis_result)
        
        # íŠ¸ë Œë“œ ë¶„ì„ ìƒì„±
        logger.info("Generating trend analysis...")
        trend_analysis = analyzer.generate_trend_analysis(analysis_result)
        
        # í–¥ìƒëœ Slack Webhook ì „ì†¡
        logger.info("Sending enhanced Slack webhook...")
        send_enhanced_slack_webhook(analysis_result, ai_suggestions, trend_analysis)
        
        logger.info("Enhanced YouTube trend analysis completed successfully!")
        
    except Exception as e:
        logger.error(f"Error in main execution: {e}", exc_info=True)
        
        # ì—ëŸ¬ ì•Œë¦¼ ì „ì†¡
        error_payload = {
            "text": f"âš ï¸ YouTube íŠ¸ë Œë“œ ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
        }
        requests.post(slack_webhook_url, json=error_payload)
        
        sys.exit(1)


if __name__ == "__main__":
    main()