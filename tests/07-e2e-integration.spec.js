// í¬ì»¤ íŠ¸ë Œë“œ ë¶„ì„ í”Œë«í¼ - End-to-End í†µí•© í…ŒìŠ¤íŠ¸
const { test, expect } = require('@playwright/test');
const { spawn } = require('child_process');
const path = require('path');
const fs = require('fs');

test.describe('End-to-End Integration Tests', () => {
  const testResultsDir = path.join(__dirname, '..', 'test-results');
  let integrationTestResults = {};
  
  test.beforeAll(async () => {
    // í†µí•© í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ì‹œì‘
    integrationTestResults = {
      sessionId: `e2e-${Date.now()}`,
      startTime: new Date().toISOString(),
      components: [],
      workflows: [],
      errors: []
    };
    
    if (!fs.existsSync(testResultsDir)) {
      fs.mkdirSync(testResultsDir, { recursive: true });
    }
  });

  test.afterAll(async () => {
    // í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
    integrationTestResults.endTime = new Date().toISOString();
    integrationTestResults.duration = Date.now() - new Date(integrationTestResults.startTime).getTime();
    
    const resultPath = path.join(testResultsDir, 'e2e-integration-results.json');
    fs.writeFileSync(resultPath, JSON.stringify(integrationTestResults, null, 2));
    
    console.log(`ğŸ¯ E2E í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ê²°ê³¼: ${resultPath}`);
  });

  test('ì „ì²´ ì‹œìŠ¤í…œ ì›Œí¬í”Œë¡œìš° ì‹œë®¬ë ˆì´ì…˜', async () => {
    const workflowScript = `
import json
import time
from datetime import datetime, date

class PokerTrendWorkflow:
    def __init__(self):
        self.workflow_state = {
            "current_step": 0,
            "completed_steps": [],
            "errors": [],
            "start_time": datetime.now().isoformat()
        }
        
        self.workflow_steps = [
            "schedule_determination",
            "pokernews_collection", 
            "pokernews_analysis",
            "youtube_data_collection",
            "youtube_analysis",
            "platform_data_collection",
            "platform_analysis",
            "slack_reporting"
        ]
    
    def simulate_schedule_determination(self):
        """ìŠ¤ì¼€ì¤„ ê²°ì • ë‹¨ê³„ ì‹œë®¬ë ˆì´ì…˜"""
        try:
            # ì˜¤ëŠ˜ì´ ì›”ìš”ì¼ì¸ì§€ í™•ì¸í•˜ì—¬ ë¦¬í¬íŠ¸ íƒ€ì… ê²°ì •
            today = date.today()
            day_of_week = today.weekday() + 1  # 1=ì›”ìš”ì¼
            
            if day_of_week == 1:
                # ì²«ì§¸ì£¼ì¸ì§€ í™•ì¸
                day_of_month = today.day
                week_of_month = (day_of_month - 1) // 7 + 1
                
                if week_of_month == 1:
                    report_type = "monthly"
                else:
                    report_type = "weekly"
            elif 2 <= day_of_week <= 5:
                report_type = "daily"
            else:
                report_type = "none"
            
            self.workflow_state["schedule_result"] = {
                "date": today.isoformat(),
                "report_type": report_type,
                "should_execute": report_type != "none"
            }
            
            return {"success": True, "report_type": report_type}
            
        except Exception as e:
            self.workflow_state["errors"].append(f"Schedule determination failed: {str(e)}")
            return {"success": False, "error": str(e)}
    
    def simulate_pokernews_pipeline(self):
        """PokerNews íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜"""
        try:
            # RSS ìˆ˜ì§‘ ì‹œë®¬ë ˆì´ì…˜
            rss_data = {
                "articles": [
                    {"title": "WSOP 2025 ì—…ë°ì´íŠ¸", "url": "https://example.com/1"},
                    {"title": "ì˜¨ë¼ì¸ í¬ì»¤ íŠ¸ë Œë“œ", "url": "https://example.com/2"},
                    {"title": "í”„ë¡œ ì„ ìˆ˜ ì¸í„°ë·°", "url": "https://example.com/3"}
                ],
                "collected_at": datetime.now().isoformat(),
                "total_articles": 3
            }
            
            # AI ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜
            analysis_result = {
                "main_topics": ["tournament", "online_poker", "strategy"],
                "sentiment_score": 7.5,
                "trend_keywords": ["WSOP", "ì˜¨ë¼ì¸", "ì „ëµ"],
                "summary": "í¬ì»¤ í† ë„ˆë¨¼íŠ¸ì™€ ì˜¨ë¼ì¸ í¬ì»¤ í™œë™ì´ ì¦ê°€í•˜ëŠ” ì¶”ì„¸"
            }
            
            self.workflow_state["pokernews_result"] = {
                "rss_data": rss_data,
                "analysis": analysis_result
            }
            
            return {"success": True, "articles_analyzed": 3}
            
        except Exception as e:
            self.workflow_state["errors"].append(f"PokerNews pipeline failed: {str(e)}")
            return {"success": False, "error": str(e)}
    
    def simulate_youtube_pipeline(self):
        """YouTube ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œë®¬ë ˆì´ì…˜"""
        try:
            # YouTube íŠ¸ë Œë“œ ë°ì´í„° ì‹œë®¬ë ˆì´ì…˜
            youtube_data = {
                "trending_videos": [
                    {
                        "title": "Texas Hold'em Strategy Guide",
                        "views": 125000,
                        "likes": 8500,
                        "channel": "PokerPro Channel"
                    },
                    {
                        "title": "í¬ì»¤ í† ë„ˆë¨¼íŠ¸ í•˜ì´ë¼ì´íŠ¸",
                        "views": 98000,
                        "likes": 6200,
                        "channel": "Korean Poker TV"
                    }
                ],
                "analysis_period": "last_24h",
                "total_videos_analyzed": 50
            }
            
            # Gemini AI ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜
            ai_insights = {
                "popular_topics": ["strategy", "tournament", "cash_game"],
                "content_quality_score": 8.2,
                "engagement_rate": 0.068,
                "trend_direction": "increasing",
                "korean_summary": "ì „ëµ ì½˜í…ì¸ ì™€ í† ë„ˆë¨¼íŠ¸ ê´€ë ¨ ì˜ìƒì˜ ì¸ê¸°ê°€ ìƒìŠ¹ ì¤‘"
            }
            
            self.workflow_state["youtube_result"] = {
                "raw_data": youtube_data,
                "ai_analysis": ai_insights
            }
            
            return {"success": True, "videos_analyzed": 50}
            
        except Exception as e:
            self.workflow_state["errors"].append(f"YouTube pipeline failed: {str(e)}")
            return {"success": False, "error": str(e)}
    
    def simulate_platform_analysis(self):
        """í”Œë«í¼ ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜"""
        try:
            # Firebase ë°ì´í„° ìˆ˜ì§‘ ì‹œë®¬ë ˆì´ì…˜
            platform_data = {
                "online_players": 45230,
                "cash_games_active": 1247,
                "tournament_entries": 892,
                "daily_growth": 5.2,
                "peak_hours": "20:00-23:00 KST"
            }
            
            # ì¼ì¼ ë¹„êµ ë¶„ì„
            comparison_result = {
                "vs_yesterday": {
                    "players": "+5.2%",
                    "cash_games": "+3.1%", 
                    "tournaments": "+8.7%"
                },
                "vs_last_week": {
                    "players": "+12.5%",
                    "cash_games": "+9.3%",
                    "tournaments": "+15.2%"
                }
            }
            
            self.workflow_state["platform_result"] = {
                "current_data": platform_data,
                "comparison": comparison_result
            }
            
            return {"success": True, "data_points_processed": 500}
            
        except Exception as e:
            self.workflow_state["errors"].append(f"Platform analysis failed: {str(e)}")
            return {"success": False, "error": str(e)}
    
    def simulate_slack_reporting(self):
        """Slack ë¦¬í¬íŒ… ì‹œë®¬ë ˆì´ì…˜"""
        try:
            # í†µí•© ë¦¬í¬íŠ¸ ìƒì„±
            integrated_report = {
                "report_type": self.workflow_state.get("schedule_result", {}).get("report_type", "daily"),
                "timestamp": datetime.now().isoformat(),
                "components": {
                    "pokernews": self.workflow_state.get("pokernews_result"),
                    "youtube": self.workflow_state.get("youtube_result"), 
                    "platform": self.workflow_state.get("platform_result")
                },
                "summary": "ëª¨ë“  êµ¬ì„±ìš”ì†Œì˜ ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë¨"
            }
            
            # Slack ë©”ì‹œì§€ ì „ì†¡ ì‹œë®¬ë ˆì´ì…˜
            slack_result = {
                "message_sent": True,
                "webhook_response": "ok",
                "delivery_time": datetime.now().isoformat()
            }
            
            self.workflow_state["slack_result"] = {
                "report": integrated_report,
                "delivery": slack_result
            }
            
            return {"success": True, "report_sent": True}
            
        except Exception as e:
            self.workflow_state["errors"].append(f"Slack reporting failed: {str(e)}")
            return {"success": False, "error": str(e)}
    
    def execute_full_workflow(self):
        """ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        workflow_methods = [
            ("schedule_determination", self.simulate_schedule_determination),
            ("pokernews_pipeline", self.simulate_pokernews_pipeline),
            ("youtube_pipeline", self.simulate_youtube_pipeline),
            ("platform_analysis", self.simulate_platform_analysis),
            ("slack_reporting", self.simulate_slack_reporting)
        ]
        
        results = {}
        
        for step_name, method in workflow_methods:
            print(f"Executing {step_name}...")
            result = method()
            results[step_name] = result
            
            if result["success"]:
                self.workflow_state["completed_steps"].append(step_name)
                print(f"  âœ“ {step_name} completed successfully")
            else:
                print(f"  âœ— {step_name} failed: {result.get('error', 'Unknown error')}")
                break
        
        self.workflow_state["end_time"] = datetime.now().isoformat()
        self.workflow_state["total_duration"] = (
            datetime.now() - datetime.fromisoformat(self.workflow_state["start_time"])
        ).total_seconds()
        
        return {
            "workflow_state": self.workflow_state,
            "step_results": results,
            "overall_success": len(self.workflow_state["errors"]) == 0
        }

# ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
print("ğŸš€ í¬ì»¤ íŠ¸ë Œë“œ ë¶„ì„ í”Œë«í¼ - End-to-End ì›Œí¬í”Œë¡œìš° ì‹œë®¬ë ˆì´ì…˜")
print("=" * 70)

workflow = PokerTrendWorkflow()
final_result = workflow.execute_full_workflow()

print("\\nğŸ“Š ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼:")
print(f"  ì „ì²´ ì„±ê³µ: {'âœ“' if final_result['overall_success'] else 'âœ—'}")
print(f"  ì™„ë£Œëœ ë‹¨ê³„: {len(final_result['workflow_state']['completed_steps'])}/{len(workflow.workflow_steps)}")
print(f"  ì´ ì‹¤í–‰ ì‹œê°„: {final_result['workflow_state']['total_duration']:.2f}ì´ˆ")

if final_result["workflow_state"]["errors"]:
    print(f"  ì˜¤ë¥˜ ë°œìƒ: {len(final_result['workflow_state']['errors'])}ê°œ")
    for error in final_result["workflow_state"]["errors"]:
        print(f"    - {error}")

print("\\nE2E ì›Œí¬í”Œë¡œìš° ì‹œë®¬ë ˆì´ì…˜: COMPLETED")
`;
    
    const tempScript = path.join(testResultsDir, 'temp_e2e_workflow.py');
    fs.writeFileSync(tempScript, workflowScript);
    
    const result = await runPythonScript(tempScript, []);
    
    expect(result.output).toContain('í¬ì»¤ íŠ¸ë Œë“œ ë¶„ì„ í”Œë«í¼ - End-to-End ì›Œí¬í”Œë¡œìš° ì‹œë®¬ë ˆì´ì…˜');
    expect(result.output).toContain('ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ê²°ê³¼');
    expect(result.output).toContain('COMPLETED');
    
    // í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ì— ê¸°ë¡
    integrationTestResults.workflows.push({
      name: 'full_system_workflow',
      success: result.output.includes('ì „ì²´ ì„±ê³µ: âœ“'),
      output: result.output
    });
    
    // ì„ì‹œ íŒŒì¼ ì •ë¦¬
    if (fs.existsSync(tempScript)) {
      fs.unlinkSync(tempScript);
    }
  });

  test('êµ¬ì„±ìš”ì†Œ ê°„ ë°ì´í„° íë¦„ ê²€ì¦', async () => {
    const dataFlowScript = `
import json
from datetime import datetime

class DataFlowValidator:
    def __init__(self):
        self.data_contracts = {
            "schedule_to_components": {
                "required_fields": ["report_type", "date", "should_execute"],
                "types": {"report_type": str, "date": str, "should_execute": bool}
            },
            "pokernews_to_integration": {
                "required_fields": ["articles", "analysis_summary", "timestamp"],
                "types": {"articles": list, "analysis_summary": dict, "timestamp": str}
            },
            "youtube_to_integration": {
                "required_fields": ["trending_data", "ai_insights", "processed_count"],
                "types": {"trending_data": list, "ai_insights": dict, "processed_count": int}
            },
            "platform_to_integration": {
                "required_fields": ["current_stats", "comparison_data", "growth_metrics"],
                "types": {"current_stats": dict, "comparison_data": dict, "growth_metrics": dict}
            },
            "integration_to_slack": {
                "required_fields": ["report_type", "components", "summary", "timestamp"],
                "types": {"report_type": str, "components": dict, "summary": str, "timestamp": str}
            }
        }
    
    def validate_data_contract(self, contract_name, data):
        """ë°ì´í„° ê³„ì•½ ê²€ì¦"""
        if contract_name not in self.data_contracts:
            return {"valid": False, "error": f"Unknown contract: {contract_name}"}
        
        contract = self.data_contracts[contract_name]
        validation_result = {
            "valid": True,
            "missing_fields": [],
            "type_mismatches": [],
            "extra_fields": []
        }
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        for field in contract["required_fields"]:
            if field not in data:
                validation_result["missing_fields"].append(field)
                validation_result["valid"] = False
        
        # íƒ€ì… ê²€ì¦
        for field, expected_type in contract["types"].items():
            if field in data and not isinstance(data[field], expected_type):
                validation_result["type_mismatches"].append({
                    "field": field,
                    "expected": expected_type.__name__,
                    "actual": type(data[field]).__name__
                })
                validation_result["valid"] = False
        
        return validation_result
    
    def simulate_data_flow(self):
        """ë°ì´í„° íë¦„ ì‹œë®¬ë ˆì´ì…˜"""
        flow_results = {}
        
        # 1. ìŠ¤ì¼€ì¤„ ê²°ì • â†’ êµ¬ì„±ìš”ì†Œë“¤
        schedule_data = {
            "report_type": "daily",
            "date": "2025-08-08",
            "should_execute": True
        }
        flow_results["schedule_validation"] = self.validate_data_contract(
            "schedule_to_components", schedule_data
        )
        
        # 2. PokerNews â†’ í†µí•©
        pokernews_data = {
            "articles": [
                {"title": "Test Article", "url": "https://test.com"},
            ],
            "analysis_summary": {
                "main_topic": "tournament",
                "sentiment": "positive"
            },
            "timestamp": datetime.now().isoformat()
        }
        flow_results["pokernews_validation"] = self.validate_data_contract(
            "pokernews_to_integration", pokernews_data
        )
        
        # 3. YouTube â†’ í†µí•©
        youtube_data = {
            "trending_data": [
                {"title": "Test Video", "views": 1000}
            ],
            "ai_insights": {
                "popular_topics": ["strategy"],
                "trend_score": 8.5
            },
            "processed_count": 50
        }
        flow_results["youtube_validation"] = self.validate_data_contract(
            "youtube_to_integration", youtube_data
        )
        
        # 4. Platform â†’ í†µí•©
        platform_data = {
            "current_stats": {
                "online_players": 45000,
                "active_games": 1200
            },
            "comparison_data": {
                "vs_yesterday": "+5.2%"
            },
            "growth_metrics": {
                "weekly_growth": 12.5,
                "monthly_growth": 35.8
            }
        }
        flow_results["platform_validation"] = self.validate_data_contract(
            "platform_to_integration", platform_data
        )
        
        # 5. í†µí•© â†’ Slack
        integration_data = {
            "report_type": "daily",
            "components": {
                "pokernews": pokernews_data,
                "youtube": youtube_data,
                "platform": platform_data
            },
            "summary": "All components processed successfully",
            "timestamp": datetime.now().isoformat()
        }
        flow_results["slack_validation"] = self.validate_data_contract(
            "integration_to_slack", integration_data
        )
        
        return flow_results

# ë°ì´í„° íë¦„ ê²€ì¦ ì‹¤í–‰
print("ğŸ”„ êµ¬ì„±ìš”ì†Œ ê°„ ë°ì´í„° íë¦„ ê²€ì¦")
print("=" * 50)

validator = DataFlowValidator()
flow_results = validator.simulate_data_flow()

overall_success = True
for contract_name, result in flow_results.items():
    status = "âœ“" if result["valid"] else "âœ—"
    print(f"{contract_name}: {status}")
    
    if not result["valid"]:
        overall_success = False
        if result["missing_fields"]:
            print(f"  Missing fields: {result['missing_fields']}")
        if result["type_mismatches"]:
            for mismatch in result["type_mismatches"]:
                print(f"  Type mismatch - {mismatch['field']}: expected {mismatch['expected']}, got {mismatch['actual']}")

print(f"\\në°ì´í„° íë¦„ ê²€ì¦ ê²°ê³¼: {'SUCCESS' if overall_success else 'FAILED'}")
print("Data flow validation: COMPLETED")
`;
    
    const tempScript = path.join(testResultsDir, 'temp_data_flow.py');
    fs.writeFileSync(tempScript, dataFlowScript);
    
    const result = await runPythonScript(tempScript, []);
    
    expect(result.output).toContain('êµ¬ì„±ìš”ì†Œ ê°„ ë°ì´í„° íë¦„ ê²€ì¦');
    expect(result.output).toContain('Data flow validation: COMPLETED');
    
    // í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ì— ê¸°ë¡
    integrationTestResults.components.push({
      name: 'data_flow_validation',
      success: result.output.includes('SUCCESS'),
      output: result.output
    });
    
    // ì„ì‹œ íŒŒì¼ ì •ë¦¬
    if (fs.existsSync(tempScript)) {
      fs.unlinkSync(tempScript);
    }
  });

  test('ì‹œìŠ¤í…œ ë³µì›ë ¥ ë° ì¥ì•  ì²˜ë¦¬ í…ŒìŠ¤íŠ¸', async () => {
    const resilienceScript = `
import random
import time
from datetime import datetime

class SystemResilienceTest:
    def __init__(self):
        self.failure_scenarios = [
            "api_rate_limit",
            "network_timeout", 
            "invalid_response",
            "service_unavailable",
            "quota_exceeded"
        ]
        
        self.recovery_strategies = {
            "api_rate_limit": "exponential_backoff",
            "network_timeout": "retry_with_timeout",
            "invalid_response": "fallback_data",
            "service_unavailable": "skip_and_continue",
            "quota_exceeded": "switch_to_cache"
        }
    
    def simulate_failure(self, component, failure_type):
        """ì‹¤íŒ¨ ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜"""
        failure_details = {
            "component": component,
            "failure_type": failure_type,
            "timestamp": datetime.now().isoformat(),
            "severity": "medium"
        }
        
        # ì‹¤íŒ¨ ì‹¬ê°ë„ ê²°ì •
        if failure_type in ["service_unavailable", "quota_exceeded"]:
            failure_details["severity"] = "high"
        elif failure_type in ["network_timeout"]:
            failure_details["severity"] = "low"
        
        return failure_details
    
    def simulate_recovery(self, failure_details):
        """ë³µêµ¬ ì „ëµ ì‹œë®¬ë ˆì´ì…˜"""
        failure_type = failure_details["failure_type"]
        strategy = self.recovery_strategies.get(failure_type, "default_retry")
        
        recovery_result = {
            "strategy_used": strategy,
            "recovery_time": random.uniform(1, 10),  # 1-10ì´ˆ
            "success": random.choice([True, True, True, False]),  # 75% ì„±ê³µë¥ 
            "fallback_used": strategy == "fallback_data",
            "timestamp": datetime.now().isoformat()
        }
        
        return recovery_result
    
    def test_component_resilience(self, component):
        """êµ¬ì„±ìš”ì†Œë³„ ë³µì›ë ¥ í…ŒìŠ¤íŠ¸"""
        print(f"\\ní…ŒìŠ¤íŒ… {component} ë³µì›ë ¥:")
        
        component_results = []
        
        # ê° êµ¬ì„±ìš”ì†Œì— ëŒ€í•´ ë‹¤ì–‘í•œ ì‹¤íŒ¨ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸
        test_failures = random.sample(self.failure_scenarios, 3)
        
        for failure_type in test_failures:
            # ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜
            failure = self.simulate_failure(component, failure_type)
            print(f"  ğŸ”´ {failure_type} ì‹¤íŒ¨ ì‹œë®¬ë ˆì´ì…˜")
            
            # ë³µêµ¬ ì‹œë®¬ë ˆì´ì…˜
            recovery = self.simulate_recovery(failure)
            recovery_status = "âœ“" if recovery["success"] else "âœ—"
            print(f"    {recovery_status} {recovery['strategy_used']} ë³µêµ¬ ì „ëµ ({recovery['recovery_time']:.1f}ì´ˆ)")
            
            component_results.append({
                "failure": failure,
                "recovery": recovery
            })
        
        return component_results
    
    def run_full_resilience_test(self):
        """ì „ì²´ ì‹œìŠ¤í…œ ë³µì›ë ¥ í…ŒìŠ¤íŠ¸"""
        components = ["pokernews", "youtube", "platform", "slack"]
        all_results = {}
        
        for component in components:
            all_results[component] = self.test_component_resilience(component)
        
        # ì „ì²´ ê²°ê³¼ ë¶„ì„
        total_tests = sum(len(results) for results in all_results.values())
        successful_recoveries = sum(
            1 for results in all_results.values() 
            for result in results 
            if result["recovery"]["success"]
        )
        
        recovery_rate = (successful_recoveries / total_tests) * 100 if total_tests > 0 else 0
        
        print(f"\\nğŸ“Š ë³µì›ë ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        print(f"  ì´ í…ŒìŠ¤íŠ¸: {total_tests}ê°œ")
        print(f"  ì„±ê³µì  ë³µêµ¬: {successful_recoveries}ê°œ")
        print(f"  ë³µêµ¬ ì„±ê³µë¥ : {recovery_rate:.1f}%")
        
        return {
            "total_tests": total_tests,
            "successful_recoveries": successful_recoveries,
            "recovery_rate": recovery_rate,
            "component_results": all_results
        }

# ì‹œìŠ¤í…œ ë³µì›ë ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
print("ğŸ›¡ï¸ ì‹œìŠ¤í…œ ë³µì›ë ¥ ë° ì¥ì•  ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
print("=" * 50)

resilience_tester = SystemResilienceTest()
test_results = resilience_tester.run_full_resilience_test()

# ê²°ê³¼ í‰ê°€
if test_results["recovery_rate"] >= 70:
    print("\\nâœ… ì‹œìŠ¤í…œ ë³µì›ë ¥: EXCELLENT")
elif test_results["recovery_rate"] >= 50:
    print("\\nâš ï¸ ì‹œìŠ¤í…œ ë³µì›ë ¥: ACCEPTABLE")
else:
    print("\\nâŒ ì‹œìŠ¤í…œ ë³µì›ë ¥: NEEDS IMPROVEMENT")

print("\\nResilience testing: COMPLETED")
`;
    
    const tempScript = path.join(testResultsDir, 'temp_resilience_test.py');
    fs.writeFileSync(tempScript, resilienceScript);
    
    const result = await runPythonScript(tempScript, []);
    
    expect(result.output).toContain('ì‹œìŠ¤í…œ ë³µì›ë ¥ ë° ì¥ì•  ì²˜ë¦¬ í…ŒìŠ¤íŠ¸');
    expect(result.output).toContain('ë³µì›ë ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼');
    expect(result.output).toContain('COMPLETED');
    
    // í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ì— ê¸°ë¡
    integrationTestResults.components.push({
      name: 'system_resilience_test',
      success: result.output.includes('EXCELLENT') || result.output.includes('ACCEPTABLE'),
      output: result.output
    });
    
    // ì„ì‹œ íŒŒì¼ ì •ë¦¬
    if (fs.existsSync(tempScript)) {
      fs.unlinkSync(tempScript);
    }
  });

  test('í†µí•© ë³´ê³ ì„œ ìƒì„± ë° ë°°í¬ í…ŒìŠ¤íŠ¸', async () => {
    const reportingScript = `
import json
from datetime import datetime, timedelta

class IntegratedReportingSystem:
    def __init__(self):
        self.report_templates = {
            "daily": self._generate_daily_report,
            "weekly": self._generate_weekly_report,
            "monthly": self._generate_monthly_report
        }
        
        self.distribution_channels = [
            "slack_daily_channel",
            "slack_weekly_channel", 
            "slack_alerts_channel",
            "email_subscribers",
            "dashboard_update"
        ]
    
    def _generate_daily_report(self, data):
        return {
            "title": "ğŸ“Š ì¼ê°„ í¬ì»¤ íŠ¸ë Œë“œ ë¶„ì„ ë¦¬í¬íŠ¸",
            "date": data["date"],
            "sections": [
                {
                    "name": "YouTube íŠ¸ë Œë“œ",
                    "data": data.get("youtube", {}),
                    "insights": ["ì „ëµ ì½˜í…ì¸  ì¸ê¸° ìƒìŠ¹", "í† ë„ˆë¨¼íŠ¸ ì˜ìƒ ì¡°íšŒìˆ˜ ì¦ê°€"]
                },
                {
                    "name": "PokerNews ë¶„ì„", 
                    "data": data.get("pokernews", {}),
                    "insights": ["WSOP ê´€ë ¨ ê¸°ì‚¬ ì¦ê°€", "ì˜¨ë¼ì¸ í¬ì»¤ ë™í–¥ ë¦¬í¬íŠ¸"]
                },
                {
                    "name": "í”Œë«í¼ í˜„í™©",
                    "data": data.get("platform", {}),
                    "insights": ["ì¼ì¼ í”Œë ˆì´ì–´ ì¦ê°€", "í˜„ê¸ˆ ê²Œì„ í™œì„±í™”"]
                }
            ],
            "summary": "ì „ë°˜ì ìœ¼ë¡œ í¬ì»¤ ì‹œì¥ì´ ì„±ì¥ì„¸ë¥¼ ë³´ì´ê³  ìˆìŒ"
        }
    
    def _generate_weekly_report(self, data):
        return {
            "title": "ğŸ“ˆ ì£¼ê°„ í¬ì»¤ íŠ¸ë Œë“œ ì¢…í•© ë¶„ì„",
            "period": f"{data['start_date']} ~ {data['end_date']}",
            "sections": [
                {
                    "name": "ì£¼ê°„ í•˜ì´ë¼ì´íŠ¸",
                    "highlights": [
                        "YouTube ì¡°íšŒìˆ˜ ì „ì£¼ ëŒ€ë¹„ +15.3% ì¦ê°€",
                        "ì˜¨ë¼ì¸ í”Œë ˆì´ì–´ ìˆ˜ +12.7% ì¦ê°€",
                        "í† ë„ˆë¨¼íŠ¸ ì°¸ê°€ì +20.1% ì¦ê°€"
                    ]
                },
                {
                    "name": "íŠ¸ë Œë“œ ë¶„ì„",
                    "trends": data.get("trends", []),
                    "predictions": data.get("predictions", [])
                }
            ],
            "summary": "ì£¼ê°„ ì „ë°˜ì ì¸ ì„±ì¥ì„¸ ì§€ì†"
        }
    
    def _generate_monthly_report(self, data):
        return {
            "title": "ğŸ“Š ì›”ê°„ í¬ì»¤ ìƒíƒœê³„ ì¢…í•© ë¦¬í¬íŠ¸",
            "month": data["month"],
            "sections": [
                {
                    "name": "ì›”ê°„ í†µê³„",
                    "statistics": data.get("monthly_stats", {}),
                    "growth_metrics": data.get("growth_metrics", {})
                },
                {
                    "name": "ì‹œì¥ ë™í–¥",
                    "market_analysis": data.get("market_analysis", {}),
                    "competitive_landscape": data.get("competitive_analysis", {})
                },
                {
                    "name": "í–¥í›„ ì „ë§",
                    "forecasts": data.get("forecasts", []),
                    "recommendations": data.get("recommendations", [])
                }
            ],
            "summary": "ì›”ê°„ ì¢…í•© ë¶„ì„ ë° í–¥í›„ ì „ëµ ì œì‹œ"
        }
    
    def generate_integrated_report(self, report_type, raw_data):
        """í†µí•© ë³´ê³ ì„œ ìƒì„±"""
        if report_type not in self.report_templates:
            return {"error": f"Unsupported report type: {report_type}"}
        
        try:
            report_generator = self.report_templates[report_type]
            report = report_generator(raw_data)
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            report["metadata"] = {
                "generated_at": datetime.now().isoformat(),
                "report_type": report_type,
                "version": "1.0",
                "system": "poker-trend-analyzer"
            }
            
            return {"success": True, "report": report}
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def distribute_report(self, report, distribution_config):
        """ë¦¬í¬íŠ¸ ë°°í¬"""
        distribution_results = {}
        
        for channel in self.distribution_channels:
            if channel in distribution_config and distribution_config[channel]:
                # ê° ì±„ë„ë³„ ë°°í¬ ì‹œë®¬ë ˆì´ì…˜
                success_rate = {
                    "slack_daily_channel": 0.95,
                    "slack_weekly_channel": 0.98,
                    "slack_alerts_channel": 0.99,
                    "email_subscribers": 0.85,
                    "dashboard_update": 0.90
                }.get(channel, 0.90)
                
                import random
                success = random.random() < success_rate
                
                distribution_results[channel] = {
                    "attempted": True,
                    "success": success,
                    "timestamp": datetime.now().isoformat(),
                    "recipients": distribution_config.get(f"{channel}_recipients", 1)
                }
            else:
                distribution_results[channel] = {
                    "attempted": False,
                    "reason": "not_configured"
                }
        
        return distribution_results
    
    def run_full_reporting_test(self):
        """ì „ì²´ ë³´ê³  ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
        test_results = {}
        
        # ê° ë¦¬í¬íŠ¸ íƒ€ì…ë³„ í…ŒìŠ¤íŠ¸
        test_data = {
            "daily": {
                "date": "2025-08-08",
                "youtube": {"trending_videos": 50, "avg_views": 125000},
                "pokernews": {"articles": 12, "main_topic": "tournament"},
                "platform": {"online_players": 45000, "growth": 5.2}
            },
            "weekly": {
                "start_date": "2025-08-05",
                "end_date": "2025-08-11",
                "trends": ["strategy_content_up", "tournament_interest_high"],
                "predictions": ["continued_growth", "new_format_adoption"]
            },
            "monthly": {
                "month": "2025-07",
                "monthly_stats": {"total_players": 850000, "total_games": 125000},
                "market_analysis": {"growth_rate": 15.3, "market_share": "increasing"}
            }
        }
        
        distribution_config = {
            "slack_daily_channel": True,
            "slack_weekly_channel": True,
            "slack_alerts_channel": False,
            "email_subscribers": True,
            "dashboard_update": True,
            "slack_daily_channel_recipients": 25,
            "email_subscribers_recipients": 150
        }
        
        for report_type, data in test_data.items():
            print(f"\\n{report_type.upper()} ë¦¬í¬íŠ¸ í…ŒìŠ¤íŠ¸:")
            
            # ë¦¬í¬íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
            generation_result = self.generate_integrated_report(report_type, data)
            if generation_result["success"]:
                print(f"  âœ“ ë¦¬í¬íŠ¸ ìƒì„± ì„±ê³µ")
                
                # ë°°í¬ í…ŒìŠ¤íŠ¸
                distribution_result = self.distribute_report(
                    generation_result["report"], distribution_config
                )
                
                successful_distributions = sum(
                    1 for result in distribution_result.values()
                    if result.get("attempted") and result.get("success")
                )
                total_attempted = sum(
                    1 for result in distribution_result.values()
                    if result.get("attempted")
                )
                
                print(f"  âœ“ ë°°í¬ ì„±ê³µ: {successful_distributions}/{total_attempted}")
                
                test_results[report_type] = {
                    "generation": True,
                    "distribution_success_rate": successful_distributions / total_attempted if total_attempted > 0 else 0
                }
            else:
                print(f"  âœ— ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {generation_result.get('error')}")
                test_results[report_type] = {"generation": False}
        
        return test_results

# í†µí•© ë³´ê³  ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
print("ğŸ“‹ í†µí•© ë³´ê³ ì„œ ìƒì„± ë° ë°°í¬ í…ŒìŠ¤íŠ¸")
print("=" * 50)

reporting_system = IntegratedReportingSystem()
test_results = reporting_system.run_full_reporting_test()

# ì „ì²´ ê²°ê³¼ í‰ê°€
all_generated = all(result.get("generation", False) for result in test_results.values())
avg_distribution_rate = sum(
    result.get("distribution_success_rate", 0) 
    for result in test_results.values()
) / len(test_results) if test_results else 0

print(f"\\nğŸ“Š ë³´ê³  ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
print(f"  ë¦¬í¬íŠ¸ ìƒì„±: {'ëª¨ë‘ ì„±ê³µ' if all_generated else 'ì¼ë¶€ ì‹¤íŒ¨'}")
print(f"  í‰ê·  ë°°í¬ ì„±ê³µë¥ : {avg_distribution_rate:.1%}")

if all_generated and avg_distribution_rate >= 0.8:
    print("\\nâœ… í†µí•© ë³´ê³  ì‹œìŠ¤í…œ: EXCELLENT")
else:
    print("\\nâš ï¸ í†µí•© ë³´ê³  ì‹œìŠ¤í…œ: NEEDS REVIEW")

print("\\nIntegrated reporting: COMPLETED")
`;
    
    const tempScript = path.join(testResultsDir, 'temp_reporting_test.py');
    fs.writeFileSync(tempScript, reportingScript);
    
    const result = await runPythonScript(tempScript, []);
    
    expect(result.output).toContain('í†µí•© ë³´ê³ ì„œ ìƒì„± ë° ë°°í¬ í…ŒìŠ¤íŠ¸');
    expect(result.output).toContain('ë³´ê³  ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ê²°ê³¼');
    expect(result.output).toContain('COMPLETED');
    
    // í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ì— ê¸°ë¡
    integrationTestResults.components.push({
      name: 'integrated_reporting_system',
      success: result.output.includes('EXCELLENT'),
      output: result.output
    });
    
    // ì„ì‹œ íŒŒì¼ ì •ë¦¬
    if (fs.existsSync(tempScript)) {
      fs.unlinkSync(tempScript);
    }
  });
});

// Helper function: Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
async function runPythonScript(scriptPath, args = [], options = {}) {
  return new Promise((resolve) => {
    const python = spawn('python', [scriptPath, ...args], {
      stdio: ['pipe', 'pipe', 'pipe'],
      cwd: path.dirname(scriptPath),
      timeout: 60000, // E2E í…ŒìŠ¤íŠ¸ëŠ” ë” ê¸´ íƒ€ì„ì•„ì›ƒ
      ...options
    });
    
    let output = '';
    let error = '';
    
    python.stdout.on('data', (data) => {
      output += data.toString();
    });
    
    python.stderr.on('data', (data) => {
      error += data.toString();
    });
    
    python.on('close', (code) => {
      resolve({
        code,
        output: output + error,
        stdout: output,
        stderr: error
      });
    });
    
    python.on('error', (err) => {
      resolve({
        code: -1,
        output: err.message,
        stdout: '',
        stderr: err.message
      });
    });
  });
}