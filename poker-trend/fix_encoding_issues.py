#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Windows CP949 ì¸ì½”ë”© ë¬¸ì œ ìë™ ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸
E2E í…ŒìŠ¤íŠ¸ì—ì„œ ë°œê²¬ëœ ë¬¸ì œë“¤ì„ ì¼ê´„ í•´ê²°
"""

import os
import sys
import logging
from pathlib import Path
from typing import List, Dict, Any
import re

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ìœ í‹¸ë¦¬í‹° ì¶”ê°€
sys.path.append(str(Path(__file__).parent / 'backend' / 'utils'))

try:
    from encoding_utils import safe_print, safe_json_dump, safe_file_write, setup_console_encoding
    from file_utils import SafeFileHandler, ensure_dir
except ImportError:
    safe_print = print
    setup_console_encoding = lambda: None

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

class EncodingFixer:
    """ì¸ì½”ë”© ë¬¸ì œ ìë™ ìˆ˜ì • í´ë˜ìŠ¤"""
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.file_handler = SafeFileHandler()
        self.fixes_applied: List[Dict[str, Any]] = []
        
        # ìˆ˜ì • ëŒ€ìƒ íŒ¨í„´ë“¤
        self.encoding_patterns = {
            # JSON ì €ì¥ ì‹œ ì¸ì½”ë”© ë¬¸ì œ
            'json_dump_no_encoding': {
                'pattern': r'json\.dump\([^)]+\)(?!\s*,\s*ensure_ascii=)',
                'description': 'JSON dump without ensure_ascii parameter'
            },
            
            # íŒŒì¼ ì—´ê¸° ì‹œ ì¸ì½”ë”© ëˆ„ë½
            'open_no_encoding': {
                'pattern': r'open\([^)]+\)(?!\s*,\s*encoding=)',
                'description': 'File open without encoding parameter'  
            },
            
            # print í•¨ìˆ˜ ì¸ì½”ë”© ë¬¸ì œ
            'unsafe_print': {
                'pattern': r'print\s*\([^)]*[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF\uAC00-\uD7AF][^)]*\)',
                'description': 'Print with unicode characters'
            }
        }
    
    def scan_python_files(self) -> List[Path]:
        """Python íŒŒì¼ë“¤ì„ ìŠ¤ìº”"""
        python_files = []
        
        # ì£¼ìš” ë””ë ‰í† ë¦¬ì—ì„œ Python íŒŒì¼ ì°¾ê¸°
        scan_dirs = [
            self.project_root / 'backend',
            self.project_root / 'scripts', 
            self.project_root / 'tests'
        ]
        
        for scan_dir in scan_dirs:
            if scan_dir.exists():
                python_files.extend(scan_dir.rglob('*.py'))
        
        logger.info(f"ìŠ¤ìº”ëœ Python íŒŒì¼: {len(python_files)}ê°œ")
        return python_files
    
    def analyze_file(self, file_path: Path) -> Dict[str, Any]:
        """íŒŒì¼ ë¶„ì„ ë° ë¬¸ì œì  íƒì§€"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # ê° íŒ¨í„´ ê²€ì‚¬
            for pattern_name, pattern_info in self.encoding_patterns.items():
                matches = re.finditer(pattern_info['pattern'], content, re.MULTILINE)
                for match in matches:
                    line_num = content[:match.start()].count('\n') + 1
                    issues.append({
                        'type': pattern_name,
                        'line': line_num,
                        'match': match.group(),
                        'description': pattern_info['description']
                    })
            
            return {
                'file_path': file_path,
                'issues': issues,
                'has_korean_text': bool(re.search(r'[\uAC00-\uD7AF]', content)),
                'has_utf8_header': '# -*- coding: utf-8 -*-' in content
            }
            
        except Exception as e:
            logger.error(f"íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨ {file_path}: {e}")
            return {'file_path': file_path, 'issues': [], 'error': str(e)}
    
    def fix_json_dump_issues(self, file_path: Path, content: str) -> str:
        """JSON dump ì¸ì½”ë”© ë¬¸ì œ ìˆ˜ì •"""
        # json.dump(...) -> json.dump(..., ensure_ascii=False) íŒ¨í„´ ìˆ˜ì •
        pattern = r'json\.dump\(([^)]+)\)(?!\s*,\s*ensure_ascii=)'
        
        def replace_json_dump(match):
            args = match.group(1)
            # ì´ë¯¸ ensure_asciiê°€ ìˆëŠ”ì§€ í™•ì¸
            if 'ensure_ascii' not in args:
                return f'json.dump({args}, ensure_ascii=False)'
            return match.group(0)
        
        modified_content = re.sub(pattern, replace_json_dump, content)
        return modified_content
    
    def fix_file_open_issues(self, file_path: Path, content: str) -> str:
        """íŒŒì¼ ì—´ê¸° ì¸ì½”ë”© ë¬¸ì œ ìˆ˜ì •"""
        # open(...) -> open(..., encoding='utf-8') íŒ¨í„´ ìˆ˜ì •
        pattern = r'open\(([^)]+)\)(?!\s*,\s*encoding=)'
        
        def replace_open(match):
            args = match.group(1)
            # ì´ë¯¸ encodingì´ ìˆëŠ”ì§€ í™•ì¸
            if 'encoding' not in args and 'mode' in args:
                if args.count("'") >= 2 or args.count('"') >= 2:
                    return f"open({args}, encoding='utf-8')"
            elif 'encoding' not in args:
                return f"open({args}, encoding='utf-8')"
            return match.group(0)
        
        modified_content = re.sub(pattern, replace_open, content)
        return modified_content
    
    def add_encoding_header(self, content: str) -> str:
        """UTF-8 ì¸ì½”ë”© í—¤ë” ì¶”ê°€"""
        lines = content.split('\n')
        
        # ì²« ë²ˆì§¸ ì¤„ì´ shebangì¸ì§€ í™•ì¸
        has_shebang = lines and lines[0].startswith('#!')
        
        # ì´ë¯¸ ì¸ì½”ë”© í—¤ë”ê°€ ìˆëŠ”ì§€ í™•ì¸
        has_encoding = any('coding:' in line or 'coding=' in line for line in lines[:3])
        
        if not has_encoding:
            encoding_line = '# -*- coding: utf-8 -*-'
            
            if has_shebang:
                lines.insert(1, encoding_line)
            else:
                lines.insert(0, encoding_line)
        
        return '\n'.join(lines)
    
    def apply_fixes_to_file(self, file_path: Path, analysis: Dict[str, Any]) -> bool:
        """íŒŒì¼ì— ìˆ˜ì •ì‚¬í•­ ì ìš©"""
        if not analysis['issues'] and analysis.get('has_utf8_header', True):
            return True
        
        try:
            # ì›ë³¸ ë‚´ìš© ì½ê¸°
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                original_content = f.read()
            
            modified_content = original_content
            changes_made = []
            
            # JSON dump ë¬¸ì œ ìˆ˜ì •
            if any(issue['type'] == 'json_dump_no_encoding' for issue in analysis['issues']):
                new_content = self.fix_json_dump_issues(file_path, modified_content)
                if new_content != modified_content:
                    modified_content = new_content
                    changes_made.append('JSON dump encoding')
            
            # íŒŒì¼ ì—´ê¸° ë¬¸ì œ ìˆ˜ì •
            if any(issue['type'] == 'open_no_encoding' for issue in analysis['issues']):
                new_content = self.fix_file_open_issues(file_path, modified_content)
                if new_content != modified_content:
                    modified_content = new_content
                    changes_made.append('File open encoding')
            
            # UTF-8 í—¤ë” ì¶”ê°€ (í•œêµ­ì–´ í…ìŠ¤íŠ¸ê°€ ìˆê±°ë‚˜ í—¤ë”ê°€ ì—†ëŠ” ê²½ìš°)
            if analysis.get('has_korean_text', False) or not analysis.get('has_utf8_header', False):
                new_content = self.add_encoding_header(modified_content)
                if new_content != modified_content:
                    modified_content = new_content
                    changes_made.append('UTF-8 header')
            
            # ë³€ê²½ì‚¬í•­ì´ ìˆìœ¼ë©´ íŒŒì¼ ì €ì¥
            if changes_made:
                if safe_file_write(modified_content, str(file_path)):
                    self.fixes_applied.append({
                        'file': str(file_path),
                        'changes': changes_made,
                        'issues_fixed': len(analysis['issues'])
                    })
                    logger.info(f"ìˆ˜ì • ì™„ë£Œ: {file_path.name} ({', '.join(changes_made)})")
                    return True
                else:
                    logger.error(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {file_path}")
                    return False
            
            return True
            
        except Exception as e:
            logger.error(f"íŒŒì¼ ìˆ˜ì • ì‹¤íŒ¨ {file_path}: {e}")
            return False
    
    def run_comprehensive_fix(self) -> Dict[str, Any]:
        """ì¢…í•©ì ì¸ ì¸ì½”ë”© ë¬¸ì œ ìˆ˜ì •"""
        logger.info("=" * 60)
        logger.info("Windows CP949 ì¸ì½”ë”© ë¬¸ì œ ìë™ ìˆ˜ì • ì‹œì‘")
        logger.info("=" * 60)
        
        # 1. ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
        setup_console_encoding()
        
        # 2. Python íŒŒì¼ ìŠ¤ìº”
        python_files = self.scan_python_files()
        
        # 3. ê° íŒŒì¼ ë¶„ì„ ë° ìˆ˜ì •
        total_files = len(python_files)
        fixed_files = 0
        total_issues = 0
        
        for i, file_path in enumerate(python_files, 1):
            logger.info(f"ì²˜ë¦¬ ì¤‘ ({i}/{total_files}): {file_path.name}")
            
            analysis = self.analyze_file(file_path)
            
            if analysis.get('error'):
                continue
            
            total_issues += len(analysis['issues'])
            
            if self.apply_fixes_to_file(file_path, analysis):
                if analysis['issues'] or analysis.get('has_korean_text', False):
                    fixed_files += 1
        
        # 4. ê²°ê³¼ ìš”ì•½
        summary = {
            'total_files_scanned': total_files,
            'files_with_fixes': fixed_files,
            'total_issues_found': total_issues,
            'fixes_applied': self.fixes_applied,
            'success_rate': (fixed_files / total_files * 100) if total_files > 0 else 0
        }
        
        logger.info("=" * 60)
        logger.info("ì¸ì½”ë”© ë¬¸ì œ ìˆ˜ì • ì™„ë£Œ")
        logger.info("=" * 60)
        logger.info(f"ìŠ¤ìº”ëœ íŒŒì¼: {summary['total_files_scanned']}ê°œ")
        logger.info(f"ìˆ˜ì •ëœ íŒŒì¼: {summary['files_with_fixes']}ê°œ")
        logger.info(f"ë°œê²¬ëœ ë¬¸ì œ: {summary['total_issues_found']}ê°œ")
        logger.info(f"ì„±ê³µë¥ : {summary['success_rate']:.1f}%")
        
        return summary
    
    def create_environment_fix_script(self) -> str:
        """í™˜ê²½ ì„¤ì • ìˆ˜ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
        script_content = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ë° ì¸ì½”ë”© ë¬¸ì œ í•´ê²° ìŠ¤í¬ë¦½íŠ¸
ìë™ ìƒì„±ë¨
"""

import os
import sys
from pathlib import Path

def setup_poker_trend_environment():
    """í¬ì»¤ íŠ¸ë Œë“œ ë¶„ì„ í™˜ê²½ ì„¤ì •"""
    print("ğŸš€ í¬ì»¤ íŠ¸ë Œë“œ ë¶„ì„ í™˜ê²½ ì„¤ì • ì¤‘...")
    
    # 1. Windows ì½˜ì†” UTF-8 ì„¤ì •
    if sys.platform == "win32":
        try:
            os.system('chcp 65001 > nul')
            os.environ['PYTHONIOENCODING'] = 'utf-8'
            print("âœ… Windows ì½˜ì†” UTF-8 ì¸ì½”ë”© ì„¤ì • ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸  ì½˜ì†” ì¸ì½”ë”© ì„¤ì • ì‹¤íŒ¨: {e}")
    
    # 2. í•„ìˆ˜ ë””ë ‰í† ë¦¬ ìƒì„±
    required_dirs = [
        'backend/data-collector/logs',
        'backend/data-collector/reports',
        'backend/platform-analyzer/reports',
        'test-results'
    ]
    
    for dir_path in required_dirs:
        try:
            Path(dir_path).mkdir(parents=True, exist_ok=True)
            print(f"âœ… ë””ë ‰í† ë¦¬ ìƒì„±: {dir_path}")
        except Exception as e:
            print(f"âŒ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨ {dir_path}: {e}")
    
    # 3. í™˜ê²½ ë³€ìˆ˜ í™•ì¸
    required_env_vars = ['YOUTUBE_API_KEY', 'GEMINI_API_KEY', 'SLACK_WEBHOOK_URL']
    missing_vars = []
    
    for var in required_env_vars:
        if not os.getenv(var):
            missing_vars.append(var)
    
    if missing_vars:
        print("âŒ ëˆ„ë½ëœ í™˜ê²½ ë³€ìˆ˜:")
        for var in missing_vars:
            print(f"  - {var}")
        print("\\n.env íŒŒì¼ì„ í™•ì¸í•˜ê³  í•„ìš”í•œ API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    else:
        print("âœ… ëª¨ë“  í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë¨")
    
    print("\\nğŸ¯ ì„¤ì • ì™„ë£Œ! ì´ì œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
    print("  python backend/data-collector/tests/test_env_enhanced.py")

if __name__ == "__main__":
    setup_poker_trend_environment()
'''
        
        script_path = self.project_root / 'setup_environment.py'
        if safe_file_write(script_content, str(script_path)):
            logger.info(f"í™˜ê²½ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±: {script_path}")
            return str(script_path)
        else:
            logger.error("í™˜ê²½ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì‹¤íŒ¨")
            return ""

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    project_root = Path(__file__).parent
    
    # ì¸ì½”ë”© ìˆ˜ì •ê¸° ìƒì„± ë° ì‹¤í–‰
    fixer = EncodingFixer(project_root)
    
    # ì¢…í•© ìˆ˜ì • ì‹¤í–‰
    summary = fixer.run_comprehensive_fix()
    
    # í™˜ê²½ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    env_script = fixer.create_environment_fix_script()
    
    # ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±
    report_path = project_root / 'ENCODING_FIX_REPORT.md'
    report_content = f"""# Windows CP949 ì¸ì½”ë”© ë¬¸ì œ ìˆ˜ì • ë³´ê³ ì„œ

## ìˆ˜ì • ìš”ì•½
- **ìŠ¤ìº”ëœ íŒŒì¼**: {summary['total_files_scanned']}ê°œ
- **ìˆ˜ì •ëœ íŒŒì¼**: {summary['files_with_fixes']}ê°œ  
- **ë°œê²¬ëœ ë¬¸ì œ**: {summary['total_issues_found']}ê°œ
- **ì„±ê³µë¥ **: {summary['success_rate']:.1f}%

## ì ìš©ëœ ìˆ˜ì •ì‚¬í•­

### ì£¼ìš” ê°œì„ ì‚¬í•­
1. **UTF-8 ì¸ì½”ë”© í—¤ë” ì¶”ê°€**: `# -*- coding: utf-8 -*-`
2. **JSON ì €ì¥ ì‹œ ì¸ì½”ë”© ê°œì„ **: `ensure_ascii=False` ì„¤ì •
3. **íŒŒì¼ I/O ì¸ì½”ë”© ëª…ì‹œ**: `encoding='utf-8'` ì¶”ê°€
4. **ì•ˆì „í•œ ì¶œë ¥ í•¨ìˆ˜ ì ìš©**: í•œê¸€ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ê°œì„ 

### ìˆ˜ì •ëœ íŒŒì¼ ëª©ë¡
"""
    
    for fix in summary['fixes_applied']:
        report_content += f"- `{fix['file']}`: {', '.join(fix['changes'])}\n"
    
    report_content += f"""
## ë‹¤ìŒ ë‹¨ê³„

1. **í™˜ê²½ ì„¤ì • ì‹¤í–‰**:
   ```bash
   python {env_script}
   ```

2. **ê°œì„ ëœ í…ŒìŠ¤íŠ¸ ì‹¤í–‰**:
   ```bash
   python backend/data-collector/tests/test_env_enhanced.py
   ```

3. **E2E í…ŒìŠ¤íŠ¸ ì¬ì‹¤í–‰**:
   ```bash
   npx playwright test
   ```

## ê¶Œì¥ì‚¬í•­

- Windows í™˜ê²½ì—ì„œëŠ” ì½˜ì†” ì½”ë“œí˜ì´ì§€ë¥¼ UTF-8ë¡œ ì„¤ì •: `chcp 65001`
- PowerShell ì‚¬ìš© ì‹œ: `$env:PYTHONIOENCODING="utf-8"`
- ëª¨ë“  Python ìŠ¤í¬ë¦½íŠ¸ì— UTF-8 ì¸ì½”ë”© í—¤ë” í¬í•¨
- íŒŒì¼ I/O ì‹œ í•­ìƒ ì¸ì½”ë”© ëª…ì‹œ

---
ìƒì„±ì¼: {Path(__file__).stat().st_mtime}
"""
    
    if safe_file_write(report_content, str(report_path)):
        logger.info(f"ìˆ˜ì • ë³´ê³ ì„œ ìƒì„±: {report_path}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ Windows CP949 ì¸ì½”ë”© ë¬¸ì œ ìˆ˜ì • ì™„ë£Œ!")
    print("=" * 60)
    print(f"ğŸ“Š ìˆ˜ì • ê²°ê³¼: {summary['files_with_fixes']}/{summary['total_files_scanned']} íŒŒì¼")
    print(f"ğŸ“ ë³´ê³ ì„œ: {report_path}")
    if env_script:
        print(f"ğŸ”§ í™˜ê²½ ì„¤ì •: {env_script}")
    
    return summary

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)