#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ìµœì í™”ëœ í¬ì»¤ íŠ¸ë Œë“œ ë¶„ì„ê¸°
- ì–¸ì–´/êµ­ê°€ ê°ì§€ ë° ì œëª© í•œê¸€ ë²ˆì—­
- ê°„ì†Œí™”ëœ ì‡¼ì¸  ì•„ì´ë””ì–´ 1ê°œ
- ì¼ê´„ Slack ì—…ë¡œë“œ
"""

import os
import json
import logging
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
import google.generativeai as genai
from googleapiclient.discovery import build
import requests
import re

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
env_path = Path(__file__).parent.parent / '.env'
if env_path.exists():
    load_dotenv(env_path)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class OptimizedTrendAnalyzer:
    def __init__(self):
        self.youtube = build('youtube', 'v3', developerKey=os.getenv('YOUTUBE_API_KEY'))
        genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
        self.gemini_model = genai.GenerativeModel('gemini-1.5-flash')
        self.slack_webhook = os.getenv('SLACK_WEBHOOK_URL')
        
        self.keywords = [
            'poker', 'holdem', 'wsop', 'wpt', 'ept', 
            'pokerstars', 'ggpoker', 'triton poker'
        ]
    
    def detect_language_and_country(self, title, description, channel_title):
        """ì–¸ì–´ ë° êµ­ê°€ ê°ì§€"""
        text_sample = f"{title} {description[:100]} {channel_title}"
        
        # ì–¸ì–´ íŒ¨í„´ ê°ì§€
        if re.search(r'[\u0B80-\u0BFF]', text_sample):  # Tamil
            return "Tamil", "India"
        elif re.search(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]', text_sample):  # Japanese
            return "Japanese", "Japan"
        elif re.search(r'[\uAC00-\uD7AF]', text_sample):  # Korean
            return "Korean", "South Korea"
        elif re.search(r'[\u4E00-\u9FFF]', text_sample):  # Chinese
            return "Chinese", "China"
        elif re.search(r'[\u0400-\u04FF]', text_sample):  # Russian
            return "Russian", "Russia"
        elif re.search(r'[\u0590-\u05FF]', text_sample):  # Hebrew
            return "Hebrew", "Israel"
        elif re.search(r'[\u0600-\u06FF]', text_sample):  # Arabic
            return "Arabic", "Middle East"
        elif re.search(r'[Ã Ã¡Ã¢Ã£Ã¤Ã¥Ã¦Ã§Ã¨Ã©ÃªÃ«Ã¬Ã­Ã®Ã¯Ã±Ã²Ã³Ã´ÃµÃ¶Ã¸Ã¹ÃºÃ»Ã¼Ã½]', text_sample.lower()):  # European
            if 'espaÃ±ol' in text_sample.lower() or 'en franÃ§ais' in text_sample.lower():
                return "Spanish/French", "Europe"
            return "European", "Europe"
        else:
            return "English", "Global"
    
    def translate_title_to_korean(self, title, detected_language):
        """ì œëª©ì„ í•œê¸€ë¡œ ë²ˆì—­"""
        if detected_language == "Korean":
            return title
        
        try:
            if detected_language != "English":
                # ë¨¼ì € ì˜ì–´ë¡œ ë²ˆì—­ í›„ í•œê¸€ë¡œ
                translate_prompt = f"Translate this {detected_language} text to Korean briefly: {title}"
            else:
                translate_prompt = f"Translate this English text to Korean briefly: {title}"
            
            response = self.gemini_model.generate_content(translate_prompt)
            return response.text.strip()
        
        except Exception as e:
            logger.warning(f"Translation failed for {title}: {e}")
            return title  # ì›ë³¸ ë°˜í™˜
    
    def collect_enhanced_video_data(self, max_results=5):
        """í–¥ìƒëœ YouTube ì˜ìƒ ë°ì´í„° ìˆ˜ì§‘"""
        logger.info("Starting enhanced video data collection...")
        all_videos = []
        
        for keyword in self.keywords:
            try:
                request = self.youtube.search().list(
                    part='snippet',
                    q=keyword,
                    type='video',
                    maxResults=max_results,
                    order='viewCount',
                    publishedAfter='2025-08-04T00:00:00Z'
                )
                
                response = request.execute()
                videos = response.get('items', [])
                
                for video in videos:
                    video_id = video['id']['videoId']
                    snippet = video['snippet']
                    
                    # ì–¸ì–´ ë° êµ­ê°€ ê°ì§€
                    original_title = snippet.get('title', '')
                    description = snippet.get('description', '')
                    channel_title = snippet.get('channelTitle', '')
                    
                    detected_language, detected_country = self.detect_language_and_country(
                        original_title, description, channel_title
                    )
                    
                    # ê¸°ë³¸ ì •ë³´
                    video_data = {
                        'video_id': video_id,
                        'original_title': original_title,
                        'description': description[:300],  # 300ìë¡œ ì œí•œ
                        'channel_title': channel_title,
                        'channel_id': snippet.get('channelId', ''),
                        'published_at': snippet.get('publishedAt', ''),
                        'upload_date': snippet.get('publishedAt', '')[:10],
                        'keyword': keyword,
                        'url': f"https://youtube.com/watch?v={video_id}",
                        'thumbnail_url': snippet.get('thumbnails', {}).get('high', {}).get('url', ''),
                        'language': detected_language,
                        'country': detected_country
                    }
                    
                    # í•œê¸€ ë²ˆì—­ ì¶”ê°€
                    korean_title = self.translate_title_to_korean(original_title, detected_language)
                    video_data['korean_title'] = korean_title
                    
                    # ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    details = self.youtube.videos().list(
                        part='statistics,contentDetails',
                        id=video_id
                    ).execute()
                    
                    if details['items']:
                        stats = details['items'][0]['statistics']
                        content = details['items'][0]['contentDetails']
                        
                        video_data.update({
                            'view_count': int(stats.get('viewCount', 0)),
                            'like_count': int(stats.get('likeCount', 0)),
                            'comment_count': int(stats.get('commentCount', 0)),
                            'duration': content.get('duration', ''),
                            'definition': content.get('definition', ''),
                        })
                    
                    all_videos.append(video_data)
                
                logger.info(f"Collected {len(videos)} videos for keyword: {keyword}")
                
            except Exception as e:
                logger.error(f"Error collecting data for {keyword}: {e}")
        
        logger.info(f"Total videos collected: {len(all_videos)}")
        return all_videos
    
    def create_concise_analysis_prompt(self, top_videos):
        """ê°„ì†Œí™”ëœ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        video_summary = []
        for i, video in enumerate(top_videos[:5], 1):
            video_summary.append(f"""
{i}ìœ„: {video.get('korean_title', '')} ({video.get('language', '')})
- ì¡°íšŒìˆ˜: {video.get('view_count', 0):,}
- ì°¸ì—¬ìœ¨: {round((video.get('like_count', 0) / video.get('view_count', 1) * 100), 2)}%
- êµ­ê°€: {video.get('country', '')}
- ì±„ë„: {video.get('channel_title', '')}
""")
        
        videos_text = "\n".join(video_summary)
        
        prompt = f"""
í¬ì»¤ íŠ¸ë Œë“œ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ TOP 5 ì˜ìƒì„ ë¶„ì„í•˜ì—¬ ê°„ê²°í•˜ê³  ì •í™•í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”.

=== TOP 5 ì˜ìƒ ë°ì´í„° ===
{videos_text}

=== ìš”ì²­ì‚¬í•­ ===

1. **í•µì‹¬ íŠ¸ë Œë“œ (3ì¤„ ì´ë‚´)**
   - ê°€ì¥ ì£¼ëª©í•  ë§Œí•œ íŒ¨í„´ 1ê°€ì§€
   - ì–¸ì–´/ì§€ì—­ë³„ íŠ¹ì§• 1ê°€ì§€  
   - ì°¸ì—¬ìœ¨ì´ ë†’ì€ ì½˜í…ì¸  íŠ¹ì§• 1ê°€ì§€

2. **í¬ì»¤ íŒ¬ ê´€ì‹¬ì‚¬ (3ì¤„ ì´ë‚´)**
   - 1ìœ„ ê´€ì‹¬ì‚¬ì™€ ê·¼ê±°
   - 2ìœ„ ê´€ì‹¬ì‚¬ì™€ ê·¼ê±°
   - 3ìœ„ ê´€ì‹¬ì‚¬ì™€ ê·¼ê±°

3. **ìµœê³ ì˜ ì‡¼ì¸  ì•„ì´ë””ì–´ 1ê°œ**
   **ì œëª©**: [í´ë¦­ì„ ìœ ë„í•˜ëŠ” ì œëª©]
   **ì»¨ì…‰**: [30ì´ˆ ìŠ¤í† ë¦¬ë¼ì¸ - 2ì¤„ ì´ë‚´]
   **íƒ€ê²Ÿ**: [ëˆ„êµ¬ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ëŠ”ì§€]
   **ì˜ˆìƒ ì„±ê³¼**: [ì¡°íšŒìˆ˜ ì˜ˆì¸¡ê³¼ ê°„ë‹¨í•œ ê·¼ê±°]
   **í•´ì‹œíƒœê·¸**: [ìµœì í™”ëœ 5ê°œ]

ëª¨ë“  ë‹µë³€ì€ ê°„ê²°í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
"""
        return prompt
    
    def generate_concise_insights(self, videos):
        """ê°„ì†Œí™”ëœ AI ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        logger.info("Generating concise AI insights...")
        
        try:
            top_videos = sorted(videos, key=lambda x: x.get('view_count', 0), reverse=True)[:5]
            prompt = self.create_concise_analysis_prompt(top_videos)
            
            response = self.gemini_model.generate_content(prompt)
            return response.text
            
        except Exception as e:
            logger.error(f"AI insight generation failed: {e}")
            return "AI ì¸ì‚¬ì´íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    
    def create_comprehensive_slack_report(self, videos, ai_insights):
        """í¬ê´„ì ì¸ Slack ë¦¬í¬íŠ¸ (ì¼ê´„ ì „ì†¡ìš©)"""
        top_videos = sorted(videos, key=lambda x: x.get('view_count', 0), reverse=True)[:5]
        total_views = sum(v.get('view_count', 0) for v in videos)
        
        # ì–¸ì–´ë³„ í†µê³„
        language_stats = {}
        for video in top_videos:
            lang = video.get('language', 'Unknown')
            if lang not in language_stats:
                language_stats[lang] = 0
            language_stats[lang] += 1
        
        lang_summary = ", ".join([f"{lang}({count})" for lang, count in language_stats.items()])
        
        blocks = [
            {
                "type": "header",
                "text": {
                    "type": "plain_text",
                    "text": "ğŸ° Optimized Poker Trend Analysis"
                }
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"ğŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M')}\nğŸ“Š Videos: {len(videos)} | Views: {total_views:,}\nğŸŒ Languages: {lang_summary}\nğŸ“ˆ Enhanced Data: Language, Translation, Country"
                }
            },
            {
                "type": "divider"
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "*ğŸ† TOP 5 VIDEOS WITH KOREAN TRANSLATION*"
                }
            }
        ]
        
        # TOP 5 ì˜ìƒ (ë²ˆì—­ëœ ì œëª© í¬í•¨)
        for i, video in enumerate(top_videos, 1):
            original_title = video.get('original_title', '')[:40] + "..."
            korean_title = video.get('korean_title', '')[:40] + "..."
            channel = video.get('channel_title', '')
            views = video.get('view_count', 0)
            likes = video.get('like_count', 0)
            language = video.get('language', '')
            country = video.get('country', '')
            url = video.get('url', '')
            
            engagement = round((likes / views * 100), 2) if views > 0 else 0
            
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*{i}. <{url}|{korean_title}>*\nğŸ“º {channel} | ğŸŒ {language} ({country})\nğŸ“Š {views:,} views â€¢ ğŸ‘ {likes:,} â€¢ ğŸ“ˆ {engagement}%\nğŸ”¤ Original: {original_title}"
                }
            })
        
        blocks.extend([
            {
                "type": "divider"
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "*ğŸ¤– CONCISE AI INSIGHTS*"
                }
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"```{ai_insights}```"
                }
            }
        ])
        
        return {"blocks": blocks}
    
    def send_slack_notification(self, message):
        """Slack ì•Œë¦¼ ì „ì†¡"""
        try:
            response = requests.post(self.slack_webhook, json=message, timeout=30)
            if response.status_code == 200:
                logger.info("Slack notification sent successfully")
                return True
            else:
                logger.error(f"Slack notification failed: {response.status_code}")
                return False
        except Exception as e:
            logger.error(f"Slack notification error: {e}")
            return False
    
    def run_optimized_analysis(self):
        """ìµœì í™”ëœ ë¶„ì„ ì‹¤í–‰"""
        logger.info("=" * 70)
        logger.info("OPTIMIZED POKER TREND ANALYSIS")
        logger.info("=" * 70)
        
        # 1. í–¥ìƒëœ ë°ì´í„° ìˆ˜ì§‘ (ì–¸ì–´/êµ­ê°€ ê°ì§€, ë²ˆì—­ í¬í•¨)
        logger.info("Step 1: Enhanced data collection with translation...")
        videos = self.collect_enhanced_video_data()
        
        # 2. ê°„ì†Œí™”ëœ AI ì¸ì‚¬ì´íŠ¸ ìƒì„±
        logger.info("Step 2: Generating concise AI insights...")
        ai_insights = self.generate_concise_insights(videos)
        
        # 3. TOP 5 ì¶”ì¶œ
        logger.info("Step 3: Extracting TOP 5 with translations...")
        top_5 = sorted(videos, key=lambda x: x.get('view_count', 0), reverse=True)[:5]
        
        # 4. ì™„ì „í•œ ë¦¬í¬íŠ¸ ìƒì„±
        logger.info("Step 4: Creating comprehensive report...")
        report_data = {
            "timestamp": datetime.now().isoformat(),
            "analysis_type": "optimized_with_translation",
            "total_videos": len(videos),
            "data_fields": [
                "original_title", "korean_title", "language", "country", 
                "view_count", "like_count", "comment_count", "channel_title"
            ],
            "ai_insights": ai_insights,
            "top_5_videos": top_5,
            "all_videos": videos
        }
        
        # 5. íŒŒì¼ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = Path(__file__).parent / 'reports' / f'optimized_analysis_{timestamp}.json'
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        # 6. AI ì¸ì‚¬ì´íŠ¸ ë³„ë„ ì €ì¥
        insights_path = Path(__file__).parent / 'reports' / f'concise_insights_{timestamp}.txt'
        with open(insights_path, 'w', encoding='utf-8') as f:
            f.write("OPTIMIZED POKER TREND ANALYSIS\n")
            f.write("=" * 50 + "\n\n")
            f.write("TOP 5 VIDEOS (WITH TRANSLATION):\n")
            f.write("-" * 30 + "\n")
            for i, video in enumerate(top_5, 1):
                f.write(f"{i}. {video.get('korean_title', '')}\n")
                f.write(f"   Original: {video.get('original_title', '')}\n")
                f.write(f"   Language: {video.get('language', '')} ({video.get('country', '')})\n")
                f.write(f"   Performance: {video.get('view_count', 0):,} views\n\n")
            
            f.write("\nCONCISE AI INSIGHTS:\n")
            f.write("=" * 30 + "\n")
            f.write(ai_insights)
        
        logger.info(f"Report saved: {report_path}")
        logger.info(f"Insights saved: {insights_path}")
        
        # 7. ëª¨ë“  ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ í›„ ì¼ê´„ Slack ì „ì†¡
        logger.info("Step 5: Sending comprehensive Slack report...")
        slack_message = self.create_comprehensive_slack_report(videos, ai_insights)
        slack_success = self.send_slack_notification(slack_message)
        
        # 8. ê²°ê³¼ ìš”ì•½
        logger.info("=" * 70)
        logger.info("OPTIMIZED ANALYSIS COMPLETED")
        logger.info("=" * 70)
        logger.info(f"âœ… Videos analyzed: {len(videos)}")
        logger.info(f"âœ… Languages detected: {len(set(v.get('language', '') for v in top_5))}")
        logger.info(f"âœ… Translations completed: {len(top_5)}")
        logger.info(f"âœ… Concise insights generated: {'Yes' if ai_insights else 'No'}")
        logger.info(f"âœ… Slack report sent: {'Yes' if slack_success else 'No'}")
        
        return report_data

if __name__ == "__main__":
    analyzer = OptimizedTrendAnalyzer()
    analyzer.run_optimized_analysis()