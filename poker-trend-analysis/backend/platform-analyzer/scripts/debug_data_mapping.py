#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Debug data mapping issues between current and historical data
"""

import os
import sys
import json
from datetime import datetime
from typing import Dict, List, Any

# Import analyzer
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from analyze_live_data import LivePokerDataAnalyzer

def analyze_html_structure():
    """Analyze the exact HTML structure to understand data mapping issues"""
    print("=" * 100)
    print("ğŸ” HTML êµ¬ì¡° ë¶„ì„ - í˜„ì¬ vs ì´ì „ ë°ì´í„° ë§¤í•‘ ë¬¸ì œ")
    print("=" * 100)
    
    analyzer = LivePokerDataAnalyzer()
    
    try:
        response = analyzer.scraper.get('https://www.pokerscout.com', timeout=30)
        print(f"âœ… PokerScout ì—°ê²° ì„±ê³µ - Status: {response.status_code}")
        
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(response.content, 'html.parser')
        
        table = soup.find('table', {'class': 'rankTable'})
        if not table:
            print("âŒ rankTableì„ ì°¾ì„ ìˆ˜ ì—†ìŒ!")
            return
        
        print(f"âœ… rankTable ë°œê²¬")
        
        # Get header to understand column structure
        headers = table.find('tr')
        if headers:
            print("\nğŸ“‹ í…Œì´ë¸” í—¤ë” ë¶„ì„:")
            print("-" * 60)
            header_cells = headers.find_all(['th', 'td'])
            for i, cell in enumerate(header_cells):
                print(f"  Column {i}: '{cell.get_text(strip=True)}'")
        
        # Get all rows for detailed analysis
        rows = table.find_all('tr')
        print(f"\nğŸ“Š ì´ í–‰ ê°œìˆ˜: {len(rows)}")
        
        print("\n" + "=" * 100)
        print("ğŸ” ì£¼ìš” í”Œë«í¼ ìƒì„¸ HTML êµ¬ì¡° ë¶„ì„")
        print("=" * 100)
        
        # Focus on platforms with suspicious data
        suspicious_platforms = ['GGNetwork', 'PokerStars', 'Ontario']
        
        for i, row in enumerate(rows[1:], 1):  # Skip header
            # Check if this row contains suspicious platform
            row_text = row.get_text().lower()
            is_suspicious = any(platform.lower() in row_text for platform in suspicious_platforms)
            
            if is_suspicious and i <= 10:  # Only first 10 rows
                print(f"\n--- í–‰ {i}: ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í”Œë«í¼ ë°œê²¬ ---")
                
                # Show raw HTML structure
                print("ğŸ” ì›ë³¸ HTML:")
                print(str(row)[:200] + "..." if len(str(row)) > 200 else str(row))
                
                # Parse TD elements
                tds = row.find_all('td')
                print(f"\nğŸ“‹ TD ìš”ì†Œ ë¶„ì„ ({len(tds)}ê°œ):")
                
                for j, td in enumerate(tds):
                    td_id = td.get('id')
                    td_class = td.get('class')
                    td_text = td.get_text(strip=True)
                    
                    print(f"  TD[{j}]: '{td_text}' | ID='{td_id}' | Class='{td_class}'")
                    
                    # Look for nested elements
                    spans = td.find_all('span')
                    if spans:
                        for k, span in enumerate(spans):
                            span_class = span.get('class')
                            span_text = span.get_text(strip=True)
                            print(f"    â””â”€ Span[{k}]: '{span_text}' | Class='{span_class}'")
                
                # Try to identify what each field represents
                print("\nğŸ¯ ë°ì´í„° ë§¤í•‘ ì¶”ì •:")
                
                # Current online (should be TD with id='online')
                online_td = row.find('td', {'id': 'online'})
                if online_td:
                    online_span = online_td.find('span')
                    online_value = online_span.get_text(strip=True) if online_span else online_td.get_text(strip=True)
                    print(f"  í˜„ì¬ ì˜¨ë¼ì¸: '{online_value}' (TD id='online')")
                
                # Cash players (should be TD with id='cash')
                cash_td = row.find('td', {'id': 'cash'})
                if cash_td:
                    cash_value = cash_td.get_text(strip=True)
                    print(f"  í˜„ì¬ ìºì‹œ: '{cash_value}' (TD id='cash')")
                
                # Peak 24h (should be TD with id='peak')
                peak_td = row.find('td', {'id': 'peak'})
                if peak_td:
                    peak_span = peak_td.find('span')
                    peak_value = peak_span.get_text(strip=True) if peak_span else peak_td.get_text(strip=True)
                    print(f"  24ì‹œê°„ í”¼í¬: '{peak_value}' (TD id='peak')")
                
                # 7-day average (should be TD with id='avg')
                avg_td = row.find('td', {'id': 'avg'})
                if avg_td:
                    avg_value = avg_td.get_text(strip=True)
                    print(f"  7ì¼ í‰ê· : '{avg_value}' (TD id='avg')")
                
                # Hours data (TD with id='hours')
                hours_td = row.find('td', {'id': 'hours'})
                if hours_td:
                    hours_value = hours_td.get_text(strip=True)[:50]  # First 50 chars
                    print(f"  ì‹œê°„ë³„ ë°ì´í„°: '{hours_value}...' (TD id='hours')")
                
                print("\n" + "=" * 60)
        
        print("\n" + "=" * 100)
        print("ğŸ” ë°ì´í„° ë§¤í•‘ ì´ìŠˆ ë¶„ì„")
        print("=" * 100)
        
        # Analyze potential mapping issues
        print("ì ì¬ì  ë¬¸ì œì ë“¤:")
        print("1. í˜„ì¬ ì˜¨ë¼ì¸ í”Œë ˆì´ì–´ vs 7ì¼ í‰ê· ì˜ ê°’ ì°¨ì´ê°€ ê·¹ì‹¬í•¨")
        print("2. ê°™ì€ í”Œë«í¼(PokerStars)ì—ì„œ ë™ì¼í•œ í˜„ì¬ê°’ì´ ë‚˜íƒ€ë‚¨")
        print("3. Peak 24hë³´ë‹¤ í˜„ì¬ê°’ì´ í›¨ì”¬ ë†’ìŒ")
        print("4. ì¼ë¶€ í”Œë«í¼ì˜ 7ì¼ í‰ê· ì´ 0 ë˜ëŠ” ë§¤ìš° ë‚®ìŒ")
        
        print("\nê°€ëŠ¥í•œ ì›ì¸ë“¤:")
        print("1. PokerScout ì‚¬ì´íŠ¸ì˜ ë°ì´í„° ì˜¤ë¥˜")
        print("2. HTML íŒŒì‹± ì‹œ ì˜ëª»ëœ ì»¬ëŸ¼ ë§¤í•‘")
        print("3. ìŠ¤í¬ë˜í•‘ íƒ€ì´ë° ì´ìŠˆ (ë°ì´í„° ì—…ë°ì´íŠ¸ ì¤‘)")
        print("4. ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½ìœ¼ë¡œ ì¸í•œ íŒŒì‹± ì˜¤ë¥˜")
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return

def compare_data_consistency():
    """Compare data consistency across multiple scrapes"""
    print("\n" + "=" * 100)
    print("ğŸ“Š ë°ì´í„° ì¼ê´€ì„± ë¹„êµ (ë‹¤ì¤‘ ìŠ¤í¬ë˜í•‘)")
    print("=" * 100)
    
    analyzer = LivePokerDataAnalyzer()
    
    print("ğŸ”„ 3ë²ˆ ì—°ì† ë°ì´í„° ìˆ˜ì§‘í•˜ì—¬ ì¼ê´€ì„± í™•ì¸...")
    
    all_scrapes = []
    for i in range(3):
        print(f"\nìŠ¤í¬ë˜í•‘ #{i+1}...")
        data = analyzer.crawl_pokerscout_data()
        if data:
            all_scrapes.append(data)
            print(f"  âœ… {len(data)}ê°œ í”Œë«í¼ ìˆ˜ì§‘")
        else:
            print(f"  âŒ ìˆ˜ì§‘ ì‹¤íŒ¨")
    
    if len(all_scrapes) < 2:
        print("âŒ ë¹„êµí•  ìˆ˜ ìˆëŠ” ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŒ")
        return
    
    print("\n" + "=" * 100)
    print("ğŸ” ìŠ¤í¬ë˜í•‘ ê²°ê³¼ ë¹„êµ")
    print("=" * 100)
    
    # Compare first scrape with others
    base_scrape = all_scrapes[0]
    
    for scrape_num, scrape_data in enumerate(all_scrapes[1:], 2):
        print(f"\nìŠ¤í¬ë˜í•‘ #1 vs ìŠ¤í¬ë˜í•‘ #{scrape_num}:")
        print("-" * 50)
        
        # Create lookup for comparison
        base_lookup = {site['site_name']: site for site in base_scrape}
        compare_lookup = {site['site_name']: site for site in scrape_data}
        
        # Find common platforms
        common_platforms = set(base_lookup.keys()) & set(compare_lookup.keys())
        print(f"ê³µí†µ í”Œë«í¼ ìˆ˜: {len(common_platforms)}")
        
        # Check for differences in key values
        differences = []
        
        for platform in common_platforms:
            base_site = base_lookup[platform]
            compare_site = compare_lookup[platform]
            
            # Check each field
            fields = ['players_online', 'cash_players', 'peak_24h', 'seven_day_avg']
            
            for field in fields:
                base_val = base_site[field]
                compare_val = compare_site[field]
                
                if base_val != compare_val:
                    differences.append({
                        'platform': platform,
                        'field': field,
                        'scrape1': base_val,
                        f'scrape{scrape_num}': compare_val,
                        'change': compare_val - base_val if base_val > 0 else 0
                    })
        
        if differences:
            print(f"ë°œê²¬ëœ ì°¨ì´ì : {len(differences)}ê°œ")
            
            # Show top differences
            for diff in differences[:10]:
                print(f"  â€¢ {diff['platform']} - {diff['field']}: {diff['scrape1']} â†’ {diff[f'scrape{scrape_num}']} (ì°¨ì´: {diff['change']})")
        else:
            print("âœ… ì°¨ì´ì  ì—†ìŒ - ë°ì´í„° ì¼ê´€ì„± í™•ì¸")

def analyze_historical_data_source():
    """Analyze how historical data (7-day avg, peak) is sourced"""
    print("\n" + "=" * 100)
    print("ğŸ• ì´ì „ ë°ì´í„° ì†ŒìŠ¤ ë¶„ì„")
    print("=" * 100)
    
    print("7ì¼ í‰ê·  ë° 24ì‹œê°„ í”¼í¬ ë°ì´í„°ì˜ ì¶œì²˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤:")
    print()
    
    analyzer = LivePokerDataAnalyzer()
    data = analyzer.crawl_pokerscout_data()
    
    if not data:
        print("âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
        return
    
    # Analyze patterns in historical data
    print("ğŸ“‹ ì´ì „ ë°ì´í„° íŒ¨í„´ ë¶„ì„:")
    print("-" * 60)
    
    platforms_with_zero_avg = []
    platforms_with_unrealistic_ratios = []
    platforms_with_consistent_data = []
    
    for site in data:
        current = site['players_online']
        avg_7day = site['seven_day_avg']
        peak_24h = site['peak_24h']
        
        # Check for zero 7-day average
        if avg_7day == 0 and current > 0:
            platforms_with_zero_avg.append(site['site_name'])
        
        # Check for unrealistic current vs peak ratio
        if peak_24h > 0 and current > peak_24h * 3:
            ratio = current / peak_24h
            platforms_with_unrealistic_ratios.append({
                'name': site['site_name'],
                'current': current,
                'peak': peak_24h,
                'ratio': ratio
            })
        
        # Check for consistent data
        if avg_7day > 0 and peak_24h > 0 and current > 0:
            # Reasonable ranges: current should be 0.5x to 2x of 7-day avg
            if 0.5 <= current / avg_7day <= 2.0:
                platforms_with_consistent_data.append(site['site_name'])
    
    print(f"âŒ 7ì¼ í‰ê· ì´ 0ì¸ í”Œë«í¼: {len(platforms_with_zero_avg)}ê°œ")
    for platform in platforms_with_zero_avg[:5]:
        print(f"   â€¢ {platform}")
    
    print(f"\nâš ï¸ ë¹„í˜„ì‹¤ì ì¸ í˜„ì¬/í”¼í¬ ë¹„ìœ¨: {len(platforms_with_unrealistic_ratios)}ê°œ")
    for item in platforms_with_unrealistic_ratios[:5]:
        print(f"   â€¢ {item['name']}: {item['current']:,} / {item['peak']:,} = {item['ratio']:.1f}x")
    
    print(f"\nâœ… ì¼ê´€ì„± ìˆëŠ” ë°ì´í„°: {len(platforms_with_consistent_data)}ê°œ")
    for platform in platforms_with_consistent_data[:5]:
        print(f"   â€¢ {platform}")
    
    print("\n" + "=" * 100)
    print("ğŸ’¡ ê²°ë¡ ")
    print("=" * 100)
    
    total_platforms = len(data)
    problematic_ratio = (len(platforms_with_zero_avg) + len(platforms_with_unrealistic_ratios)) / total_platforms * 100
    
    print(f"ì „ì²´ í”Œë«í¼: {total_platforms}ê°œ")
    print(f"ë¬¸ì œ ìˆëŠ” í”Œë«í¼: {len(platforms_with_zero_avg) + len(platforms_with_unrealistic_ratios)}ê°œ ({problematic_ratio:.1f}%)")
    print(f"ì •ìƒ ë°ì´í„°: {len(platforms_with_consistent_data)}ê°œ ({len(platforms_with_consistent_data)/total_platforms*100:.1f}%)")
    
    if problematic_ratio > 50:
        print("\nğŸš¨ ë¬¸ì œ ì‹¬ê°ë„: ë†’ìŒ")
        print("   - PokerScout ì‚¬ì´íŠ¸ ìì²´ì˜ ë°ì´í„° í’ˆì§ˆ ì´ìŠˆë¡œ ë³´ì„")
        print("   - ì´ì „ ë°ì´í„°(7ì¼ í‰ê· , 24ì‹œê°„ í”¼í¬)ì˜ ì‹ ë¢°ì„±ì´ ë‚®ìŒ")
    elif problematic_ratio > 25:
        print("\nâš ï¸ ë¬¸ì œ ì‹¬ê°ë„: ì¤‘ê°„")
        print("   - ì¼ë¶€ í”Œë«í¼ì˜ ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ")
    else:
        print("\nâœ… ë¬¸ì œ ì‹¬ê°ë„: ë‚®ìŒ")
        print("   - ëŒ€ë¶€ë¶„ì˜ ë°ì´í„°ê°€ ì¼ê´€ì„± ìˆìŒ")

def main():
    print("=" * 100)
    print("ğŸ› ë°ì´í„° ë§¤í•‘ ë¬¸ì œ ë¶„ì„ ë„êµ¬")
    print("ğŸ“… " + datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
    print("=" * 100)
    
    # 1. HTML êµ¬ì¡° ë¶„ì„
    analyze_html_structure()
    
    # 2. ë°ì´í„° ì¼ê´€ì„± í™•ì¸
    compare_data_consistency()
    
    # 3. ì´ì „ ë°ì´í„° ì†ŒìŠ¤ ë¶„ì„
    analyze_historical_data_source()
    
    print("\n" + "=" * 100)
    print("ğŸ¯ ìµœì¢… ì§„ë‹¨")
    print("=" * 100)
    print("ë¬¸ì œì˜ ê·¼ë³¸ ì›ì¸ì€ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤:")
    print()
    print("1. ğŸŒ PokerScout ì‚¬ì´íŠ¸ ìì²´ì˜ ë°ì´í„° ì˜¤ë¥˜")
    print("   - í˜„ì¬ í”Œë ˆì´ì–´ ìˆ˜ê°€ ì‹¤ì œë³´ë‹¤ ë†’ê²Œ í‘œì‹œë¨")
    print("   - 7ì¼ í‰ê· ì´ ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šê±°ë‚˜ ì˜ëª»ëœ ê°’")
    print("   - ê°™ì€ ê°’ì´ ì—¬ëŸ¬ í”Œë«í¼ì— ì¤‘ë³µ í‘œì‹œ")
    print()
    print("2. ğŸ“Š ë°ì´í„° ì—…ë°ì´íŠ¸ íƒ€ì´ë° ì´ìŠˆ")
    print("   - í˜„ì¬ ë°ì´í„°ëŠ” ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸")
    print("   - ì´ì „ ë°ì´í„°ëŠ” ì§€ì—°ë˜ê±°ë‚˜ ìˆ˜ë™ ì—…ë°ì´íŠ¸")
    print()
    print("3. ğŸ”§ HTML êµ¬ì¡° ë³€ê²½")
    print("   - PokerScoutì´ ì‚¬ì´íŠ¸ êµ¬ì¡°ë¥¼ ë³€ê²½")
    print("   - íŒŒì‹± ë¡œì§ì´ ì˜ˆì „ êµ¬ì¡°ì— ë§ì¶°ì ¸ ìˆìŒ")
    print("=" * 100)

if __name__ == "__main__":
    main()